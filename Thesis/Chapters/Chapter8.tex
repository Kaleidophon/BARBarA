% Chapter 8

\chapter{Experiment $\mathcal{C}$: Relationsvorhersage mit Wortkontextvektoren} % Main chapter title

\label{Chapter8} % For referencing the chapter elsewhere, use \ref{Chapter1}

%----------------------------------------------------------------------------------------

In diesem Kapitel soll versucht werden, die Methodik des rauschkonstrastierenden Lernen aus Kapitel \ref{Chapter6}
auf die Wortkontextvektoren (vgl. Kapitel \ref{Chapter4}) anzuwenden und nur die Relationsvektoren zu lernen. Zu diesem Zweck
wird eine Untermenge von \textsc{FB15k} gebildet, die Tripel enthält, deren Kopf- und Fußentität jeweils als Wortvektorrepräsentation vorliegen.
Schlußendlich werden die Ergebnisse evaluiert und diskutiert.

\section{Datenerzeugung}

Zu Trainingszwecken wird eine Untermenge aus \textsc{FB15k} bzw. \textsc{GER14k} gebildet. Da
die Vektorrepräsentationen für die Entitäten nicht von Grund auf erstellt sorden mit
\verb|word2vec| trainierte Vektoren verwendert werden, können nur solche Worte in dem
neuen Trainingsset vorhanden sein, zu denen ebensolche Wortvektoren auch vorliegen.
Dies ist leider nur für einen substantiell geringeren Teil der Fall, wie in Abbildung \ref{fig:we4k} zu
erkennen ist.

\begin{table}[h]
  \centering
  \begin{changemargin}{0cm}{0cm}
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{@{}lllllll@{}}
    \toprule[1.5pt]
    \textsc{Datenset} & \multicolumn{2}{l}{\textsc{\#Tripel}} & \multicolumn{2}{l}{\textsc{\#Entitätstypen}} & \multicolumn{2}{l}{\textsc{\#Relationstypen}} \\
    \toprule
    FB15k & 592.213 & & 14.951 & & 1.345 & \\
    GER14k & 459.724 & (\textcolor{BrickRed}{$\downarrow$-22,37 \%}) & 14.334 & (\textcolor{BrickRed}{$\downarrow$-4,12 \%}) & 1.236 & (\textcolor{BrickRed}{$\downarrow$-8,1 \%}) \\
    WE4k & 50.518 & (\textcolor{BrickRed}{$\downarrow$-91,47 \%}) & 3.623 & (\textcolor{BrickRed}{$\downarrow$-74,72 \%}) & 749 & (\textcolor{BrickRed}{$\downarrow$-39,40 \%}) \\
    \bottomrule[1.25pt]
  \end{tabular}%
  }
\end{changemargin}
  \caption[Daten des neuen Relationsdatensets im Vergleich zu \textsc{FB15k} und \textsc{GER14k}]{Daten des neuen Sets \textsc{WE4k} im Vergleich mit
  \textsc{FB15k} und \textsc{GER14k}. Aufgelistet ist die Anzahl der Tripel (Datensätze), Entitäts- und Relationstypen und die Veränderung
  der Anzahlen in Prozent im Vergleich zu \textsc{FB15k} in Klammern.\label{fig:we4k}}
\end{table}

Dies ist dadurch zu erklären, dass in der Quelle der Originaldaten, nämlich \emph{Freebase},
sehr viele sehr seltene Entitäten vertreten sind. Die vielen Freiwilligen, die über die
Jahre dazu beigetragen haben, die Wissensdatenbank weiter zu vervollständigen, haben dabei auch
viele unbekanntere Filme, Personen etc. hinzugefügt, die in einem Korpus eher selten zu finden sind, sei er auch
so groß wie \textsc{Decow}.\\

Da die resultierende Menge an Tripeln gerundet ungefähr viertausend einzigartige Entitäten enthält, die auch als
Wortkontextvektoren vorliegen, wird dieses Datenset im Folgenden \textsc{WE4k} genannt.

\section{Training}

Das Training der Relationsvektoren findet in einer zu der in Kapitel \ref{Chapter6} beschrieben Methode sehr
ähnlichen Art und Weise statt: Es wird zuerst eine Menge korrumpierter Tripel erstellt, bei denen entweder
die Kopf- oder Fußentität ersetzt wurde.
Mithilfe der ursprünglichen Tripel wird eine Menge aus Tripelpaaren erstellt, von denen der korrumpierte Teil jeweils
zufällig aus $S'$ ausgewählt wird. Auch die Verlustfunktion gestaltet sich prinzipiell gleich (siehe Formel \ref{form:lossf}).\\

Die wenigen Unterschiede bestehen darin, dass diesmal nur die Repräsentationen der Relationen trainiert werden,
da die der Enitäten schon vorliegen, sowie im Trainingsschritt selbst: So wird wird wegen der geringeren Menge an
Daten darauf verzichtet, für jede Trainingsanzahl eine feste Anzahl von Tripelpaaren zufällig auszuwählen.
Stattdessen richtet sich die Größe von $S_{batch}$ nach folgender Formel\footnote{Die Addtion von 1 dient dazu, bei weniger
als 10 Tripeln für eine Relation wenigstens mit einem Tripel zu trainieren. Der Rest entspricht einer Heuristik. Es wurden
verschiedene Größen für den Minibatch ausprobiert, die jedoch keinen signifikaten Einfluss auf die Ergebnisse hatten.}:

\begin{equation}
  S_{batch} \leftarrow sample(S^*, \floor*{\frac{|S^*|}{10}}+1)
\end{equation}

\section{Evaluation}

Die Evaluation fand auf diesselbe Art und Weise wie im Abschnitt \ref{sec:transe-eval} statt. So wurde wieder untersucht,
inwiefern die Relationsvektoren und die Vektorrepräsentationen der Entitäten dazu genutzt werden können, ein Relationstripel
durch ``Raten'' zu vervollständigen und gemessen, welcher Rang der richtigen Antwort zugewiesen wurde und in wieivel Prozent
diese unter den besten Zehn anzutreffen war. Als Baseline fungierte wieder die Unstructured-Methode, wobei die Relationsvektoren
Nullvektoren entsprechen.

\begin{table}[h]
  \centering
  \begin{tabular}{lll}
    \toprule[1.5pt]
    \textsc{Datenset} & \textsc{\O\ Rang} & \textsc{Hits@10} \\
     \toprule
     \textsc{Unstr.} & & \\
     \textsc{WE4k} & 1122,03 & 5,67 \\
     \textsc{FB15k} & \textbf{197,02} & \textbf{48,79} \\
     \textsc{GER14k} & 222,05 & 41,83 \\
    \bottomrule[1.25pt]
  \end{tabular}
  \caption[Resultate auf mit Wordvektoren auf \textsc{WE3k}]{Evaluationsergebnisse von \textsc{WE4k} gegenüber denen
  von \textsc{FB15k} und \textsc{GER14k} sowie der Unstructured-Baseline.\label{fig:eval-we4k}}
\end{table}

Im Blick auf Abbildung \ref{fig:eval-we4k} zeigt ein ernüchterndes Fazit auf. So schnitt die Variante
mit Wortvektoren aus \verb|word2vec| und seperat trainierten Relationsrepräsentationen ($\rightarrow$ \textsc{WE4k}) im Bezug auf
den gemittelten Rang mehr als fünf Mal so schlecht und im Bezug auf die \textsc{Hits@10} mehr als acht Mal so schlecht ab (sic!).
Die möglichen Gründe für das weite Verfehlen guter Ergebnisse werden nun in Kapitel \ref{sec:we4k-zwifa} diskutiert.

\section{Zwischenfazit}\label{sec:we4k-zwifa}

Um die Diskrepanz zwischen den Ergebnissen mit gemeinsam trainierten Repräsentationen für Entitäten und Relationen im Vergleich
zu denen mit Wortkontext- als Entitätsvektoren zu erklären, sollte die Unterschiedlichkeit der Ansätze hervorgehoben
werden.\\

Im ersten Fall werden wie erwähnt alle eine Relation betreffende Repräsentationsvektoren gemeinsam trainiert; es ist
also davon auszugehen, dass diese bestmöglichst angepasst sind, um $\parallel h + r - t\parallel$ für alle $h, t$ zu minimieren.\\
Dies kann im zweiten Fall nicht unbedingt gewährleistet werden: Da $h$ und $t$ im Vornherein schon feststehen und nicht
an $r$ angepasst werden (sondern genau umgekehrt $r$ an $h$ und $t$ angepasst wird), kann der minimale Wert der Verlustfunktion
unter Umständen nur schwer erlangt werden.\\
Als weitere Begründungen sind anzuführen, dass
\begin{itemize}
 \item[a)] \textsc{WE4k} auf \textbf{deutlich} kleineren Datenmengen arbeitet (weshalb maschinelle
  Lernverfahren unter Umständen gar keine Lösung finden können, die gut auf ungesehene Beispiele generalisiert) und
  \item[b)] Wortkontextvektoren von sehr speziellen Entitäten enthält, die in \emph{Freebase} als Knoten existieren,
  unter Umständen aber sehr selten im Korpus auftauchen
\end{itemize}
Da die Beschaffenheit der korpusbasierten Repräsentationen vor allem von Kookkurrenzen mit anderen
Begriffen abhängt, bedeutet eine niedrige Termfrequenz vor allem weniger aussagekräftige Wortkontextvektoren, worunter die
Ergebnisse in der Konsequenz zu leiden haben.\\

Zuletzt sollte mit in Betracht gezogen werden, dass die trainierten Relationen sehr feingliedrig sind. Anderen Forschungsarbeiten,
 die mit grobaufgelösten Beziehungen wie ``Cause-Effect'' oder ``Entitiy-Origin''
(\cite{hendrickx2009semeval}) arbeiten, können dadurch auf größere Datenmengen zugreifen und bessere Ergebnisse auf
ungesehenen Beispielen erzielen.
