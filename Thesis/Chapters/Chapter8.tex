% Chapter 8

\chapter{Experiment C: Relationsvorhersage mit Wortvektorrepräsentation} % Main chapter title

\label{Chapter8} % For referencing the chapter elsewhere, use \ref{Chapter1}

%----------------------------------------------------------------------------------------

In diesem Kapitel soll versucht werden, die Methodik des Rausch-konstrastierenden Lernen aus Kapitel \ref{Chapter6}
auf die Wortvektoren (vgl. Kapitel \ref{Chapter5}) anzuwenden und nur die Relationsvektoren zu lernen. Zu diesem Zweck
wird eine Untermenge von FB15k, die Tripel enthält, deren Kopf- und Fußentität jeweils als Wortvektorrepräsentation vorliegen.
Schlußendlich werden die Ergebnisse evaluiert und diskutiert.

\section{Datenerzeugung}

Zu Trainingszwecken wird eine Untermenge aus FB15k bzw. GER14k gebildet. Da
die Vektorrepräsentationen für die Entitäten nicht von Grund auf erstellt sorden mit
\verb|word2vec| trainierte Vektoren verwendert werden, können nur solche Worte in dem
neuen Trainingsset vorhanden sein, zu denen ebensolche Wortvektoren auch vorliegen.
Dies ist leider nur für einen gerinen Teil der Fall, wie in Abbildung \ref{fig:we4k} zu
erkennen ist.

\begin{figure}[h]
  \centering
  \begin{changemargin}{0cm}{0cm}
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{r||cl|cl|cl}
    \textsc{Datenset} & \multicolumn{2}{l|}{\textsc{\#Tripel}} & \multicolumn{2}{l|}{\textsc{\#Entitätstypen}} & \multicolumn{2}{l}{\textsc{\#Relationstypen}} \\
    \hline
    FB15k & 592.213 & & 14.951 & & 1.345 & \\
    GER14k & 459.724 & (\textcolor{BrickRed}{$\downarrow$-22,37 \%}) & 14.334 & (\textcolor{BrickRed}{$\downarrow$-4,12 \%}) & 1.236 & (\textcolor{BrickRed}{$\downarrow$-8,1 \%}) \\
    WE4k & 50.518 & (\textcolor{BrickRed}{$\downarrow$-91,47 \%}) & 3.623 & (\textcolor{BrickRed}{$\downarrow$-74,72 \%}) & 749 & (\textcolor{BrickRed}{$\downarrow$-39,40 \%}) \\
  \end{tabular}%
  }
\end{changemargin}
  \caption[Daten des neuen Relationsdatensets im Vergleich zu FB15k und GER14k]{Daten des neuen Sets WE4k im Vergleich mit
  FB15k und GER14k. Aufgelistet ist die Anzahl der Tripel (Datensätze), Entitäts- und Relationstypen und die Veränderung
  der Anzahlen in Prozent im Vergleich zu FB15k in Klammern.\label{fig:we4k}}
\end{figure}

Dies ist dadurch zu erklären, dass in der Quelle der Originaldaten, nämlich Freebase,
sehr viele sehr seltene Entitäten vertreten sind. Die vielen Freiwilligen, die über die
Jahre dazu beigetragen haben, die Wissensdatenbank weiter zu vervollständigen, haben dabei auch
viele unbekanntere Filme, Personen etc. hinzugefügt, die in einem Korpus eher selten zu finden sind.\\

Da die resultierende Menge an Tripeln gerundet ungefähr viertausend einzigartig Entitäten enthält, die auch als
Wortvektorrepräsentation (\emph{word embeddings}) vorliegen, wird dieses Datenset WE4k genannt.

\section{Training}

Das Training der Relationsvektoren findet in einer sehr zu der in Kapitel \ref{Chapter6} beschrieben Methode sehr
ähnlichen Art und Weise wie in Kapitel \ref{Chapter6} statt: Es wird zuerst eine Menge korrumpierter Tripel erstellt, bei denen entweder
die Kopf- oder Fußentität ersetzt wurde.
Mithilfe der ursprünglichen Tripel wird eine Menge aus Tripelpaaren erstellt, von denen der korrumpierte Teil jeweils
zufällig aus $S'$ ausgewählt wird. Auch die Verlustfunktion gestaltet sich prinzipiell gleich.\\

Der einzige Unterschied besteht in der Implementation des Algorithmus: So wird wird wegen der geringeren Menge an
Daten darauf verzichtet, für jede Trainingsanzahl eine feste Anzahl von Tripelpaaren zufällig auszuwählen.
Stattdessen richtet sich die Größe von $S_{batch}$ nach folgender Formel:

\begin{equation}
  S_{batch} \leftarrow sample(S^*, \floor*{\frac{|S^*|}{10}}+1)\footnote{Die Addtion von 1 dient dazu, bei weniger
  von 10 Tripeln für eine Relation wenigstens mit einem Tripel zu trainieren. Der Rest ist eine Heuristik.}
\end{equation}

\section{Evaluation}

Die Evaluation fand auf diesselbe Art und Weise wie im Abschnitt \ref{sec:transe-eval} statt. So wurde wieder untersucht,
inwiefern die Relationsvektoren und die Vektorrepräsentationen der Entitäten dazu genutzt werden können, ein Relationstripel
durch ``Raten'' zu vervollständigen und gemessen, welcher Rang der richtigen Antwort zugewiesen wurde und in wieivel Prozent
diese unter den Top Zehn anzutreffen war.

\begin{figure}[h]
  \centering
  \begin{tabular}{r||c|c}
    \textsc{Datenset} & \textsc{Gemittelter Rang} & \textsc{Hits@10} \\
     \hline
     WE4k & 1122,03 & 5,67 \\
     FB15k & \textbf{197,02} & \textbf{48,79} \\
     GER14k & 222,05 & 41,83 \\
  \end{tabular}
  \caption[Resultate auf mit Wordvektoren auf WE3k]{\label{fig:eval-we4k}}
\end{figure}

Im Blick auf Abbildung \ref{fig:eval-we4k} zeigt ein ziemlich ernüchterndes Fazit auf. So schnitt die Variante
mit Wortvektoren aus \verb|word2vec| und seperat trainierten Relationsrepräsentationen ($\rightarrow$ WE4k) im Bezug auf
den gemittelten Rang mehr als fünf Mal so schlecht und im Bezug auf die Hits\@10 mehr als acht Mal so schlecht ab.\\
Die möglichen Gründe für das weite Verfehlen guter Ergebnisse werden nun in \ref{sec:we4k-zwifa} diskutiert.

\section{Zwischenfazit}\label{sec:we4k-zwifa}

Um die Diskrepanz zwischen den Ergebnissen mit gemeinsam trainierten Repräsentationen für Entitäten und Relation im Vergleich
zu denen mit auf dem Korpus trainierten Entitäsvektoren zu erklären, sollte Unterschiedlichkeit der Ansätze hervorgehoben
werden.\\
Im ersten Fall werden wie erwähnt alle zu eine Relation betreffende Repräsentationsvektoren gemeinsam trainiert; es ist
also davon auszugehen, dass diese bestmöglichst angepasst sind, um $|h + r - t|$ für alle $h, t$ zu minimieren.\\
Dies kann im zweiten Fall nicht unbedingt gewährleistet werden: Da $h$ und $t$ im Vornherein schon feststehen und nicht
an $r$ angepasst werden (sondern genau umkehrt $r$ an $h$ und $t$ angepasst wird), kann der minimale Wert der Verlustfunktion
unter Umständen nur schwer erlangt werden.\\
Als eine weitere Begründung ist anzuführen, dass a) WE4k auf deutlich kleineren Datenmengen arbeitet (weshalb maschinelle
Lernverfahren unter umständen gar keine Lösung finden können, die gut auf ungesehene Beispiele generalisiert) und b)
Wortvektoren von sehr speziellen Entitäten enthält, die in \emph{Freebase} als Knoten existieren, u. U. aber sehr selten
im Korpus auftauchen. Da die Beschaffenheit der korpusbasierten Repräsentationen vor allem von Kookkurrenzen mit anderen
Begriffen abhängt, bedeutet eine niedrige Termfrequenz vor allem weniger aussagekräftige Wortvektoren, worunter die
Ergebnisse in der Konsequenz zu leiden haben.\\
Zuletzt sollte mit in Betracht gezogen werden, dass die trainierten Relationen sehr feingliedrig sind. Im Gegensatz zu
anderen Forschungsarbeiten, die mit grobaufgelösten Beziehungen wie ``Cause-Effect'' oder ``Entitiy-Origin''
(\cite{hendrickx2009semeval}) arbeiten, können dadurch am größere Datenmengen zugreifen und bessere Ergebnisse auf
ungesehenen Beispielen erziehlen.
