% Chapter 9

\chapter{Fazit} % Main chapter title

\label{Chapter9} % For referencing the chapter elsewhere, use \ref{Chapter1}

%----------------------------------------------------------------------------------------

\begin{itquote}
  Mit dem Wissen wächst der Zweifel.
  \flushright
  \textsc{Johann Wolfgang von Goethe}
\end{itquote}

\section{Zusammenfassung}

In dieser Arbeit wurden verschiedene Möglichkeiten präsentiert, Wissen aus Wissensdatenbanken durch kontinuierliche Vektoren
zu repräsentieren. In Kapitel \ref{Chapter6} wurden unterschiedlich komplexe Herangehesweisen vorgestellt, Repräsentationen
für Entitäten und Relationen einer solchen Datenbank gleichzeitig zu mithilfe von Methoden des Maschinellen Lernens zu trainieren.\\
Für das TransE genannte Verfahren wurden zusätzlich Ergebnisse mit einer deutschsprachigen Untermenge der Daten (GER14k)
durchgeführt, die zwar bei der Evaluation etwas schlechter ausfielen, aber dennoch vergleichbar waren.\\

In Kapitel \ref{Chapter7} wurde ein eigener Versuch unternommen, ähnliche Ergebnisse mithilfe von Wortvektorrepräsentationen
zu erreichen, zur deren Erstellung das Tool \emph{word2vec} verwendet wurde, welches auf großen Korpora arbeitet. Dazu
wurde der deutschsprachige Internetkorpus DECOW14X aufbereitet.\\
Im Folgenden wurde angestrebt, Wortvektorpaare durch ihre Differenzvektoren verschiedenen Relationen zuzuteilen. Dies schlug
jedoch fehl, da der Ansatz auf einem Trugschluss fußte. Deshalb konnten keine evaluierbaren Ergebnisse erzeugt werden.
Eine ausführliche Diskussion darüber findet sich im letzten Abschnitt von Kapitel \ref{Chapter7}.

\section{Diskussion}

Die Implikationen der in dieser Arbeit gewonnenen Erkenntnisse sollte mit Bedacht diskutiert werden. Das Fehlschlagen
eines Ansatzes auf der Basis von Wortvektorrepräsentationen heißt im Umkehrschluss nicht, dass alle Vorstöße in dieser
Richtung zum Scheitern verurteilt sind (im Gegenteil soll darauf im nächsten Abschnitt eingegangen werden).\\
Es scheint jedoch leichter, Repräsentationen gleich im Kontext der Struktur einer Wissensdatenbank als im
Kontext eines großen Korpus zu trainieren, da diese so von Anfang an auf dafür wichtige Eigenschaften getrimmt werden
(nämliche die Beziehung zu anderen Relevanten Entitäten).\\

Das Fehlschlagen des vorgestellten Ansatzes in Kapitel \ref{Chapter7} scheint vor allem auf einen Fehler in der
Grundannahme und die schlechte Skalierbarkeit zurückzuführen. Um Letzteres zu verhindern, könnten in zukünftigen Ansätzen
weitere Informationsquellen hinzugezogen werden, um ``sinnvolle'' von ``sinnlosen'' Wortpaaren zu trennen. Da davon
auszugehen ist, dass in der Menge aller Möglichen Wortpaare nur ein sehr kleiner Prozentsatz tatsächlich Sinn ergeben
dürfte, sollte dieses Vorgehen die totale Rechenzeit signifikaten verringern.\\
Der der Hypothese zugrunde liegende logische Fehler scheint im Nachhinein offensichtlich. Jedoch war dieser schwer
vorherzusehen, nachdem in vielen anderen Arbeiten die semantischen Eigenschaften von arithmentischen Rechnungen mit
Wortvektoren so stark hervorgehoben werden. Zudem wird dieser Aspekt immer nur anhand von in einer offensichtlichen
Beziehung zueinander stehenden Wortpaaren illustriert. Dadurch fiel dieses Versäumnis erst auf, als es aus zeitliche Gründen
nicht mehr möglich war, im Rahmen dieser Abschlussarbeit andere Verfahren zu testen und zudem Versuche, auf Basis der
vorliegenden Daten diesen Fehler zu korrigieren fehlgeschlagen waren.

\section{Ausblick}

Der vorliegende Ansatz bietet vielerlei Möglichkeiten zur Verbesserung. Im Folgenden sollen einige davon skizziert werden:\\
Zuallerst erscheint es sinnvoll, das Konzept von einem unüberwachten zu einem überwachten Ansatz zu ändern, sprich einer
maschinellen Lernmethode mit Daten zu versorgen, denen bereits eine Klasse zugewiesen wurde. Beispielweise könnten eine
sog. \emph{Support Vector Machine} (SVM) oder ein anderer Lernalgorithmus ein zu einer bestimmten Relation gehöriges Wortpaar
als Eingabe nehmen, um anhand dessen lernen zu unterscheiden, welche Differenzvektoren für eine spezifische Relationsart
charakteristisch sind. Innerhalb des gesamten Forschungsbereichs des maschinellen Lernens ergeben sich so dutzende Möglichkeiten,
sei es mit verschiedenen Features oder Algorithmen, z.B. SVMs mit Kerneln oder Neuralen Netzwerken. Es könnte für jede
Relation eine Klasse (plus ggf. eine Klasse für Wortpaare ohne Relation) definiert werden, denen später unklassifizierte
Wortpaare zugeordnet werden.\\

Die durch auf dem Korpus erstellten Wortvektoren sind ein sehr aktuelles Forschungsthema. Verschiedene Ansätze wurden
präsentiert, diese weiter zu verbessern, beispielweise auf Depenzgrammatik basierede Repräsentationen von (\cite{levy2014dependency}).
Es wäre interessant herauszufinden, inwiefern sich diese auf die Performanz eines Systems zur Relationsvorhersage
auswirken.
