% Chapter 9

\chapter{Fazit} % Main chapter title

\label{Chapter9} % For referencing the chapter elsewhere, use \ref{Chapter1}

%----------------------------------------------------------------------------------------

\begin{itquote}
  ``Mit dem Wissen wächst der Zweifel.''
  \flushright
  \textsc{Johann Wolfgang von Goethe}
\end{itquote}

\section{Zusammenfassung}

In dieser Arbeit wurden verschiedene Möglichkeiten präsentiert, Wissen aus Wissensdatenbanken durch kontinuierliche Vektorrepräsentationen
darzustellen und zu erweitern. In Kapitel \ref{Chapter6} wurden unterschiedlich komplexe Herangehesweisen vorgestellt, Repräsentationen
für Entitäten und Relationen einer solchen Datenbank gleichzeitig zu mithilfe von Methoden des Maschinellen Lernens zu trainieren.\\
Für das TransE genannte Verfahren wurden zusätzlich Ergebnisse mit einer deutschsprachigen Untermenge der Daten (\textsc{GER14k})
durchgeführt, die zwar bei der Evaluation etwas schlechter ausfielen, aber dennoch vergleichbar waren.\\

In Kapitel \ref{Chapter7} wurde ein eigener Versuch unternommen, ähnliche Ergebnisse mithilfe von Wortkontextvektoren
zu erreichen, zur deren Erstellung das Tool \verb|word2vec| verwendet wurde, welches auf großen Korpora arbeitet. Dazu
wurde der deutschsprachige Internetkorpus \textsc{DECOW14X} aufbereitet.\\
Im Folgenden wurde angestrebt, Wortvektorpaare durch ihre Differenzvektoren verschiedenen Relationen zuzuteilen. Dies schlug
jedoch fehl, da der Ansatz auf einem Trugschluss fußte. Deshalb konnten keine evaluierbaren Ergebnisse erzeugt werden.
Eine ausführliche Diskussion darüber findet sich in \ref{sec:zwi-dis}.\\

In Kapitel \ref{Chapter8} wurde versucht, Wortkontextvektoren in das Verfahren von \ref{Chapter6} einzubinden und nur
noch Vektorrepräsentationen für Relationen zu trainieren. Hierfür wurde ebenfalls ein Datenset namens \textsc{WE4k}
erzeugt. Wegen der Datenknappheit und anderen in \ref{sec:we4k-zwifa} diskutierten Gründen konnten hierbei keine vergleichbaren Ergebnisse
erlangt werden. Dennoch konnten einige Erkenntnisse über Wortkontextvektoren im Speziellen und Vektorrepräsentationen
daraus gezogen werden, die im nächsten Abschnitt reflektiert werden.

\section{Diskussion}

Die Implikationen der in dieser Arbeit gewonnenen Erkenntnisse sollte mit Bedacht diskutiert werden. Das Fehlschlagen
eines Ansatzes auf der Basis von Wortkontextvektoren heißt im Umkehrschluss nicht, dass alle Vorstöße in dieser
Richtung zum Scheitern verurteilt sind (im Gegenteil soll darauf in \ref{sec:fazit-ausblick} eingegangen werden).\\
Es scheint jedoch unbestreitbar leichter, Repräsentationen gleich im Kontext der Struktur einer Wissensdatenbank als im
Kontext eines großen Korpus zu trainieren, da diese so von Anfang an auf dafür wichtige Eigenschaften getrimmt werden
(nämliche die Beziehung zu anderen Relevanten Entitäten). Jedoch erfordern solche Repräsentationen bereits viele
vorstrukturierte Datensätze, die von Menschen erstellt werden müssen.\\

Das Fehlschlagen des vorgestellten Ansatzes in Kapitel \ref{Chapter7} scheint vor allem auf einen Fehler in der
Grundannahme und die schlechte Skalierbarkeit zurückzuführen sein. Um Letzteres zu verhindern, könnten in zukünftigen Ansätzen
weitere Informationsquellen hinzugezogen werden, um ``sinnvolle'' von ``sinnlosen'' Wortpaaren zu trennen. Da davon
auszugehen ist, dass in der Menge aller Möglichen Wortpaare nur ein sehr kleiner Prozentsatz tatsächlich Sinn ergeben
dürfte, sollte dieses Vorgehen die totale Rechenzeit signifikaten verringern.\\
Der der Hypothese zugrunde liegende logische Fehler scheint im Nachhinein offensichtlich. Dieser war aber schwer
vorherzusehen, nachdem in vielen anderen Arbeiten die semantischen Eigenschaften von arithmentischen Rechnungen mit
Wortvektoren so stark hervorgehoben werden. Zudem wird dieser Aspekt immer nur anhand von in einer offensichtlichen
Beziehung zueinander stehenden Wortpaaren illustriert. Dadurch fiel dieses Versäumnis erst auf, als es aus zeitliche Gründen
nicht mehr möglich war, im Rahmen dieser Abschlussarbeit andere Verfahren zu testen und zudem Versuche, auf Basis der
vorliegenden Daten diesen Fehler zu korrigieren fehlgeschlagen waren.

\section{Ausblick}\label{sec:fazit-ausblick}

Der vorliegende Ansatz bietet vielerlei Möglichkeiten zur Verbesserung. Im Folgenden sollen einige davon skizziert werden:\\
Zuallerst erscheint es sinnvoll, das Konzept von einem unüberwachten zu einem überwachten Ansatz zu ändern, sprich einer
maschinellen Lernmethode mit Daten zu versorgen, denen bereits eine Klasse zugewiesen wurde. Beispielweise könnten eine
sog. \emph{Support Vector Machine} (SVM) oder ein anderer Lernalgorithmus ein zu einer bestimmten Relation gehöriges Wortpaar
als Eingabe nehmen, um anhand dessen lernen zu unterscheiden, welche Differenzvektoren für eine spezifische Relationsart
charakteristisch sind. Sollte es bei einem unüberwachten Ansatz bleiben, sollten zusätzliche Informationen einer anderen Domäne
den Daten angefügt werden.\\
Innerhalb des gesamten Forschungsbereichs des maschinellen Lernens ergeben sich so dutzende Möglichkeiten,
sei es mit verschiedenen Features oder Algorithmen, z.B. SVMs mit Kerneln oder Neuronalen Netzwerken. Es könnte für jede
Relation eine Klasse (plus ggf. eine Klasse für Wortpaare ohne Relation) definiert werden, denen später unklassifizierte
Wortpaare zugeordnet werden.\\

Die durch auf dem Korpus erstellten Wortvektoren sind ein sehr aktuelles Forschungsthema. Verschiedene Ansätze wurden
präsentiert, diese weiter zu verbessern, beispielweise auf Depenzgrammatik basierede Repräsentationen von (\cite{levy2014dependency}),
oder die als \emph{GloVe} bekanntgewordenen globalen Wortvektoren von (\cite{pennington2014glove}).
Es wäre interessant herauszufinden, inwiefern sich diese auf die Performanz eines Systems zur Relationsvorhersage
auswirken.\\

Zudem sollte sich auf eher grober aufgelöste Relationen wie in (\cite{hendrickx2009semeval}), da dies im Bezug
auf zweierlei Probleme Abhilfe verschaffen dürfte: Weil diese sich auf weniger spezielle Entitäten beziehen, ist gewährleistet,
dass die dazugehörigen Wortkontextvektoren qualitativ besser sind. Außerdem ist es in diesem Fall wahrscheinlicher, dass
sich ebenjene Relationen als Differenzvektor identifizieren lassen als wesentlich seltenere und spezielle Relationen wie
in \textsc{FB14k}.\\
Das daraus gewonnene Ergebnisse selbst in dieser Auflösungebene hilfreich sind, wird in der Einleitung von (\cite{hendrickx2009semeval})
dargestellt:

\begin{itquote}
    ``The automatic recognition of semantic relations has many applications, such as information extraction,
    document summarization, machine translation, or construction of thesauri and semantic networks[,] [...]
    word sense disambiguation, language modeling, para- phrasing, and recognizing textual entailment.''
\end{itquote}

Abschließend bleibt festzustellen, dass Wortkontextvektoren nur eine von vielen verschiedenen Arten von kontinuerlichen
Wortvektorrepräsentationen sind, die in ihren Eigenschaft zwar beim Lösen vieler Probleme der maschinellen Sprachverarbeiten
neue Ansätze geliefert haben, aber auch nicht für jede Problemstellung als Werkzeug nützlich erscheinen.\\
Stattdessen sollten im Vornherein immer genau die Anforderungen und die Vor- und Nachteile verschiedenster Repräsentationen
gegeneinander abgewogen werden.\\
Der Wert dieser Arbeit besteht unter Anderem demnach darin, Grenzen der Wortkontextvektoren aufgezeigt zu haben, die sich abseits
des berühmten Beispiels

\begin{quote}
  $\vec{v}(King) - \vec{v}(Man) + \vec{v}(Woman) \approx \vec{v}(Queen)$
\end{quote}

in der Begeisterung über diese Eigenschaft nur schwer erkennen lassen.
