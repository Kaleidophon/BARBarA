% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\usepackage{iftex}

\ifPDFTeX
  \usepackage[utf8]{inputenc}
\fi
\ifdefined\DeclareUnicodeCharacter
  \DeclareUnicodeCharacter{00A0}{\nobreakspace}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}
\usepackage{eqparbox}


\addto\captionsenglish{\renewcommand{\figurename}{Fig.\@ }}
\addto\captionsenglish{\renewcommand{\tablename}{Table }}
\SetupFloatingEnvironment{literal-block}{name=Listing }

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{4}


\title{BARBarA Documentation}
\date{Jul 31, 2016}
\release{v1.0}
\author{BARBarA}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ch\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@mb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@cpf\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\renewcommand\PYGZsq{\textquotesingle}

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}


(a \textbf{B} ad \textbf{A} cronym \textbf{R} egarding a \textbf{Ba} chelo \textbf{r} \textbf{A} ssignment)


\chapter{src}
\label{index:welcome-to-barbara-s-documentation}\label{index:src}

\section{src package}
\label{src::doc}\label{src:src-package}
The \code{src} package contains all code used in this project.
It is divided into multiple packages:
\begin{itemize}
\item {} 
\code{src.clustering}: Clustering of mapping vectors.

\item {} 
\code{src.eval}: Evaluation of word embeddings

\item {} 
\code{src.mapping}: Creation of mapping vectors from word embedding pairs.

\item {} 
\code{src.misc}: Helper function and decorators.

\item {} 
\code{src.prep}: Scripts used for different preparations steps for fundamental resources.

\item {} 
\code{src.trans\_e}: \emph{TransE} related preparation scripts as well as \emph{TransE} inspired Training with word embeddings.

\end{itemize}


\subsection{Subpackages}
\label{src:subpackages}

\subsubsection{src.clustering package}
\label{src.clustering:src-clustering-package}\label{src.clustering::doc}

\paragraph{Submodules}
\label{src.clustering:submodules}

\paragraph{src.clustering.cluster\_mappings module}
\label{src.clustering:module-src.clustering.cluster_mappings}\label{src.clustering:src-clustering-cluster-mappings-module}\index{src.clustering.cluster\_mappings (module)}
Script to cluster mapping vectors created with {\hyperref[src.mapping:module\string-src.mapping.mapthreading]{\crossref{\code{src.mapping.mapthreading}}}}.
\index{aggregate\_cluster() (in module src.clustering.cluster\_mappings)}

\begin{fulllineitems}
\phantomsection\label{src.clustering:src.clustering.cluster_mappings.aggregate_cluster}\pysiglinewithargsret{\bfcode{aggregate\_cluster}}{\emph{points}, \emph{labels}}{}
Arranges all clusters in a list, where a sublist with all points at index i corresponds with the
custer with label i.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{points}} (\emph{\texttt{list}}) -- List of datapoints

\item {} 
\textbf{\texttt{labels}} (\emph{\texttt{list}}) -- List of unique cluster labels

\end{itemize}

\item[{Returns}] \leavevmode
list of lists of datapoints belonging to the i-th cluster

\item[{Return type}] \leavevmode
list

\end{description}\end{quote}

\end{fulllineitems}

\index{cluster\_mappings() (in module src.clustering.cluster\_mappings)}

\begin{fulllineitems}
\phantomsection\label{src.clustering:src.clustering.cluster_mappings.cluster_mappings}\pysiglinewithargsret{\bfcode{cluster\_mappings}}{\emph{vector\_inpath}, \emph{do\_pca=False}, \emph{target\_dim=100}, \emph{indices\_inpath=None}, \emph{epsilon=2.625}, \emph{min\_s=20}}{}
Cluster mapping vectors created with {\hyperref[src.mapping:module\string-src.mapping.mapthreading]{\crossref{\code{src.mapping.mapthreading}}}} or \code{rc.mapping.map\_vectors.py}.
Because just reading about the number of clusters and their sizes, there's an option to resolve the indices of
the vectors in the cluster to their original word pairs.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{vector\_inpath}} (\emph{\texttt{str}}) -- Path to vector file. File should have the following format (separated by spaces):
\textless{}index of original vector \#1\textgreater{} \textless{}index of original vector \#2\textgreater{} \textless{}Dimension 1\textgreater{} ... \textless{}Dimension n\textgreater{}

\item {} 
\textbf{\texttt{do\_pca}} (\emph{\texttt{bool}}) -- Flag to indicate whether PCA should be executed before clustering to reduce amount of

\item {} 
\textbf{\texttt{computation.}} -- 

\item {} 
\textbf{\texttt{target\_dim}} (\emph{\texttt{int}}) -- Number of dimensions vectors should be shrunk to in case PCA is performed.

\item {} 
\textbf{\texttt{indices\_inpath}} (\emph{\texttt{str}}) -- Path to file with the indices given to words. The file should have the following format:
\textless{}index of word\textgreater{} \textless{}word\textgreater{} (separated by tab)

\item {} 
\textbf{\texttt{epsilon}} (\emph{\texttt{float}}) -- Radius of circle DBSCAN uses to look for other data points.

\item {} 
\textbf{\texttt{min\_s}} (\emph{\texttt{int}}) -- Minimum number of points in radius epsilon DBSCAN needs to declare a point a core object.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_cluster\_size() (in module src.clustering.cluster\_mappings)}

\begin{fulllineitems}
\phantomsection\label{src.clustering:src.clustering.cluster_mappings.get_cluster_size}\pysiglinewithargsret{\bfcode{get\_cluster\_size}}{\emph{labels}}{}
Calculate the size of every cluster found by DBSCAN.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{labels}} (\emph{\texttt{list}}) -- List of cluster IDs assigned to every data point.

\item[{Returns}] \leavevmode
Dictionary of cluster sizes with cluster id as key and cluster size as value.

\item[{Return type}] \leavevmode
defaultdict

\end{description}\end{quote}

\end{fulllineitems}

\index{init\_argparser() (in module src.clustering.cluster\_mappings)}

\begin{fulllineitems}
\phantomsection\label{src.clustering:src.clustering.cluster_mappings.init_argparser}\pysiglinewithargsret{\bfcode{init\_argparser}}{}{}
Initialize all possible arguments for the argument parser.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
ArgumentParser object with command line arguments for this script.

\item[{Return type}] \leavevmode
\code{argparse.ArgumentParser}

\end{description}\end{quote}

\end{fulllineitems}

\index{load\_indices() (in module src.clustering.cluster\_mappings)}

\begin{fulllineitems}
\phantomsection\label{src.clustering:src.clustering.cluster_mappings.load_indices}\pysiglinewithargsret{\bfcode{load\_indices}}{\emph{indices\_inpath}}{}
Load word indices from a file. The file should have the following format: \textless{}index of word\textgreater{}       \textless{}word\textgreater{} (separated by
tab)
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{indices\_inpath}} (\emph{\texttt{str}}) -- Path to index file.

\end{description}\end{quote}

\end{fulllineitems}

\index{load\_mappings\_from\_model() (in module src.clustering.cluster\_mappings)}

\begin{fulllineitems}
\phantomsection\label{src.clustering:src.clustering.cluster_mappings.load_mappings_from_model}\pysiglinewithargsret{\bfcode{load\_mappings\_from\_model}}{\emph{mapping\_inpath}}{}
Load mapping vectors from file.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{mapping\_inpath}} -- Path mapping vector file.

\item[{Returns}] \leavevmode
A tuple of a list of word index pairs and a dictionary (defaultdict) with index pair tuple as key
and mapping vector (as numpy.array) as value.

\item[{Return type}] \leavevmode
tuple

\end{description}\end{quote}

\end{fulllineitems}

\index{main() (in module src.clustering.cluster\_mappings)}

\begin{fulllineitems}
\phantomsection\label{src.clustering:src.clustering.cluster_mappings.main}\pysiglinewithargsret{\bfcode{main}}{}{}
This is the main function. It uses the parsed command line arguments to pick the right function to execute.

\end{fulllineitems}

\index{resolve\_indices() (in module src.clustering.cluster\_mappings)}

\begin{fulllineitems}
\phantomsection\label{src.clustering:src.clustering.cluster_mappings.resolve_indices}\pysiglinewithargsret{\bfcode{resolve\_indices}}{\emph{points}, \emph{labels}, \emph{indices\_inpath}}{}
Resolves the indices of word pairs found in a cluster to their real names.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{points}} (\emph{\texttt{list}}) -- List of datapoints

\item {} 
\textbf{\texttt{labels}} (\emph{\texttt{list}}) -- List of unique cluster labels

\item {} 
\textbf{\texttt{indices\_inpath}} (\emph{\texttt{str}}) -- Path to file with the indices given to words. The file should have the following format:
\textless{}index of word\textgreater{} \textless{}word\textgreater{} (separated by tab)

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{train\_clustering\_parameters() (in module src.clustering.cluster\_mappings)}

\begin{fulllineitems}
\phantomsection\label{src.clustering:src.clustering.cluster_mappings.train_clustering_parameters}\pysiglinewithargsret{\bfcode{train\_clustering\_parameters}}{\emph{vector\_inpath}}{}
Functions that tries to figure out the optimal clustering parameters in regard to DBSCAN's epsilon,
min\_samples and p.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{vector\_inpath}} (\emph{\texttt{str}}) -- Path to vector file. File has to have the following format (separated by spaces):
\textless{}index of original vector \#1\textgreater{} \textless{}index of original vector \#2\textgreater{} \textless{}Dimension 1\textgreater{} ... \textless{}Dimension n\textgreater{}

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{Module contents}
\label{src.clustering:module-contents}\label{src.clustering:module-src.clustering}\index{src.clustering (module)}

\subsubsection{src.eval package}
\label{src.eval::doc}\label{src.eval:src-eval-package}

\paragraph{Submodules}
\label{src.eval:submodules}

\paragraph{src.eval.analogy module}
\label{src.eval:module-src.eval.analogy}\label{src.eval:src-eval-analogy-module}\index{src.eval.analogy (module)}
Module to evaluate word embeddings by the means of analogies like ``W is to X like Y is to Z''. Usually,
the system uses the word embeddings of word W, X, Y and tries to find the vector of word Z that is most similar to
X and Y and most dissimilar to W.
Therefore, the \href{https://transacl.org/ojs/index.php/tacl/article/viewFile/570/124}{CosMul method (Levy et al., 2015)}
is used.

The whole module is used in \code{src.eval.eval\_vectors.py}.
\index{analogy\_eval() (in module src.eval.analogy)}

\begin{fulllineitems}
\phantomsection\label{src.eval:src.eval.analogy.analogy_eval}\pysiglinewithargsret{\bfcode{analogy\_eval}}{\emph{vector\_inpath}, \emph{analogy\_path}, \emph{per\_section=False}}{}
Perform analogy evaluation. Usually, the system uses the word embeddings of word W, X, Y and tries to find the
vector of word Z that is most similar to
X and Y and most dissimilar to W for an analogy like ``W is to X like Y is to Z.''
Therefore, the CosMul method (Levy et al., 2015) is used.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{vector\_inpath}} (\emph{\texttt{str}}) -- Path to \titleref{word2vec} vector file.

\item {} 
\textbf{\texttt{analogy\_path}} (\emph{\texttt{str}}) -- Path to analogy file.

\item {} 
\textbf{\texttt{per\_section}} (\emph{\texttt{bool}}) -- Flag to indicate whether analogies test should be conducted section-wise or just all in
one run.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{read\_analogies() (in module src.eval.analogy)}

\begin{fulllineitems}
\phantomsection\label{src.eval:src.eval.analogy.read_analogies}\pysiglinewithargsret{\bfcode{read\_analogies}}{\emph{analogy\_path}, \emph{per\_section=False}}{}
Reads a file with analogies.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{analogy\_path}} (\emph{\texttt{str}}) -- Path to analogy file.

\item {} 
\textbf{\texttt{per\_section}} (\emph{\texttt{bool}}) -- Flag to indicate whether analogies test should be conducted section-wise or just all in
one run. In this function, the section will be put into a data structure accordingly.

\end{itemize}

\item[{Returns}] \leavevmode
Dictionary with section header as key, list of analogy as 4-tuples as value.

\item[{Return type}] \leavevmode
dict

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{src.eval.eval\_vectors module}
\label{src.eval:src-eval-eval-vectors-module}\label{src.eval:module-src.eval.eval_vectors}\index{src.eval.eval\_vectors (module)}\begin{description}
\item[{Main module used to evaluate word embeddings. It offers the following options:}] \leavevmode
\begin{DUlineblock}{0em}
\item[] 1.) Analogy: The system tries to complete an analogy like ``W is to X like Y is to...?'' The percentage
of correct answers is measured.
\item[] 2.) Word similarity: The system assign word pairs a similarity score based on the cosine similarity of their
word embeddings. Then, to correlation between those and human ratings is measured with Pearson's rho.
\item[] 3.) Nearest neighbors: Find the nearest neighbors for a list of words based on their word embeddings. Good for
a first look on the data, but not quantifiable.
\item[] 4.) Visualize: Plot word embeddings in 2D or 3D. Fancy plots. Yay!
\end{DUlineblock}

\end{description}
\index{find\_nearest\_neighbors() (in module src.eval.eval\_vectors)}

\begin{fulllineitems}
\phantomsection\label{src.eval:src.eval.eval_vectors.find_nearest_neighbors}\pysiglinewithargsret{\bfcode{find\_nearest\_neighbors}}{\emph{vector\_inpath}, \emph{max\_n}, \emph{wordlist}}{}
Find the nearest neighbors for a list of words based on their word embeddings.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{vector\_inpath}} (\emph{\texttt{str}}) -- Path to vector file. File has to have the following format (separated by spaces):
\textless{}index of original vector \#1\textgreater{} \textless{}index of original vector \#2\textgreater{} \textless{}Dimension 1\textgreater{} ... \textless{}Dimension n\textgreater{}

\item {} 
\textbf{\texttt{max\_n}} (\emph{\texttt{int}}) -- Number of nearest neighbors that should be determined.

\item {} 
\textbf{\texttt{wordlist}} (\emph{\texttt{list}}) -- List of words nearest neighbors should be found for.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{init\_argparser() (in module src.eval.eval\_vectors)}

\begin{fulllineitems}
\phantomsection\label{src.eval:src.eval.eval_vectors.init_argparser}\pysiglinewithargsret{\bfcode{init\_argparser}}{}{}
Initialize all possible arguments for the argument parser.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
ArgumentParser object with command line arguments for this script.

\item[{Return type}] \leavevmode
\code{argparse.ArgumentParser}

\end{description}\end{quote}

\end{fulllineitems}

\index{main() (in module src.eval.eval\_vectors)}

\begin{fulllineitems}
\phantomsection\label{src.eval:src.eval.eval_vectors.main}\pysiglinewithargsret{\bfcode{main}}{}{}
This is the main function. It uses the parsed command line arguments, especially \titleref{--mode}, to pick the right
function to execute.

\end{fulllineitems}

\index{plot() (in module src.eval.eval\_vectors)}

\begin{fulllineitems}
\phantomsection\label{src.eval:src.eval.eval_vectors.plot}\pysiglinewithargsret{\bfcode{plot}}{\emph{vector\_inpath}, \emph{max\_n}, \emph{target\_dim}, \emph{show\_plot=False}, \emph{display\_names=False}}{}
Plot word embeddings in 2D or 3D. As a heuristic, word will only be plotted after the 50th most frequent words to
avoid plotting boring stop words.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{vector\_inpath}} (\emph{\texttt{str}}) -- Path to vector file. File has to have the following format (separated by spaces):
\textless{}index of original vector \#1\textgreater{} \textless{}index of original vector \#2\textgreater{} \textless{}Dimension 1\textgreater{} ... \textless{}Dimension n\textgreater{}

\item {} 
\textbf{\texttt{max\_n}} (\emph{\texttt{int}}) -- Maximum number of vectors to be plotted.

\item {} 
\textbf{\texttt{show\_plot}} (\emph{\texttt{bool}}) -- Flag to indicate whether a window with the (interactive) plot should pop up after executing
the script.

\item {} 
\textbf{\texttt{display\_names}} (\emph{\texttt{bool}}) -- Flag to indicate whether the words should acutally be shown next to the data point in
the plot. Can get very messy with higher \titleref{max\_n}.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{src.eval.word\_similarity module}
\label{src.eval:src-eval-word-similarity-module}\label{src.eval:module-src.eval.word_similarity}\index{src.eval.word\_similarity (module)}
Module used to conduct the word similarity evaluation. The system assign word pairs a similarity score based on
the cosine similarity of their word embeddings. Then, to correlation between those and human ratings is measured with
Pearson's rho.

The whole module is used in \code{src.eval.eval\_vectors.py}.
\index{evaluate\_wordpair\_sims() (in module src.eval.word\_similarity)}

\begin{fulllineitems}
\phantomsection\label{src.eval:src.eval.word_similarity.evaluate_wordpair_sims}\pysiglinewithargsret{\bfcode{evaluate\_wordpair\_sims}}{\emph{x}, \emph{y}, \emph{number\_of\_pairs}}{}
Evaluate results of the similarity score assignments, i.e. calculate pearson's rho and its significance.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{x}} (\emph{\texttt{list}}) -- List of similarity scores assigned by humans.

\item {} 
\textbf{\texttt{y}} (\emph{\texttt{list}}) -- List of similarity scores assigned by the system.

\item {} 
\textbf{\texttt{number\_of\_pairs}} (\emph{\texttt{int}}) -- Number of word pairs evaluated.

\end{itemize}

\item[{Returns}] \leavevmode
\textbf{rho} -- Pearson's correlation coefficient.
t (float): Student's t value.
z (float): z value.

\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}

\index{read\_wordpairs() (in module src.eval.word\_similarity)}

\begin{fulllineitems}
\phantomsection\label{src.eval:src.eval.word_similarity.read_wordpairs}\pysiglinewithargsret{\bfcode{read\_wordpairs}}{\emph{wordpair\_path}, \emph{format='google'}}{}
Read wordpair file with wordpairs and their similarity scores assigned by humans.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{wordpair\_path}} (\emph{\texttt{str}}) -- Path to word pair file.

\item {} 
\textbf{\texttt{format}} (\emph{\texttt{str}}) -- Format of wor pair file \{google\textbar{}semrel\}

\end{itemize}

\item[{Returns}] \leavevmode
Tuple of a list of word pairs and a list of similarity scores for those same pair assigned by humans.

\item[{Return type}] \leavevmode
tuple

\end{description}\end{quote}

\end{fulllineitems}

\index{remove\_unknowns() (in module src.eval.word\_similarity)}

\begin{fulllineitems}
\phantomsection\label{src.eval:src.eval.word_similarity.remove_unknowns}\pysiglinewithargsret{\bfcode{remove\_unknowns}}{\emph{x}, \emph{y}}{}
Remove word pairs from the results where one or two word embedding weren't found.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{x}} (\emph{\texttt{list}}) -- List of similarity scores assigned by humans.

\item {} 
\textbf{\texttt{y}} (\emph{\texttt{list}}) -- List of similarity scores assigned by the system.

\end{itemize}

\item[{Returns}] \leavevmode
\textbf{x} -- Purged list of similarity scores assigned by humans.
y (list): Purged list of similarity scores assigned by the system.

\item[{Return type}] \leavevmode
list

\end{description}\end{quote}

\end{fulllineitems}

\index{word\_sim\_eval() (in module src.eval.word\_similarity)}

\begin{fulllineitems}
\phantomsection\label{src.eval:src.eval.word_similarity.word_sim_eval}\pysiglinewithargsret{\bfcode{word\_sim\_eval}}{\emph{vector\_inpath}, \emph{wordpair\_path}, \emph{format='google'}}{}
Function that let's the system assign word pairs a similarity score based on the cosine similarity of their word
embeddings. Then, to correlation between those and human ratings is measured with Pearson's rho.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{vector\_inpath}} (\emph{\texttt{str}}) -- Path to vector file. File has to have the following format (separated by spaces):
\textless{}index of original vector \#1\textgreater{} \textless{}index of original vector \#2\textgreater{} \textless{}Dimension 1\textgreater{} ... \textless{}Dimension n\textgreater{}

\item {} 
\textbf{\texttt{wordpair\_path}} (\emph{\texttt{str}}) -- Path to word pair file.

\item {} 
\textbf{\texttt{format}} (\emph{\texttt{str}}) -- Format of word pair file \{google\textbar{}semrel\}

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{Module contents}
\label{src.eval:module-src.eval}\label{src.eval:module-contents}\index{src.eval (module)}

\subsubsection{src.mapping package}
\label{src.mapping::doc}\label{src.mapping:src-mapping-package}

\paragraph{Submodules}
\label{src.mapping:submodules}

\paragraph{src.mapping.mapthreading module}
\label{src.mapping:src-mapping-mapthreading-module}\label{src.mapping:module-src.mapping.mapthreading}\index{src.mapping.mapthreading (module)}
Module used to map a pair of vectors into a new combined vector space. Those mappings will be created by multiple
threads in a master-slave-pattern. To do so, the user can choose between different vector operations as offset, cosine
similarity, euclidean distance and many more.

\begin{notice}{warning}{Warning:}
Because of \(\Omega=\frac{n(n-1)}{2}\), it is recommended to use the co-occurrence constraint
\(\Lambda\), which limits the calculations to word embedding pairs which words occurred together in a corpus in
at least \emph{n} sentences (but it will still take quite a while).
\end{notice}
\index{MappingMasterThread (class in src.mapping.mapthreading)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.MappingMasterThread}\pysiglinewithargsret{\strong{class }\bfcode{MappingMasterThread}}{\emph{n}, \emph{vector\_inpath}, \emph{vector\_outpath}, \emph{features}, \emph{lambda\_}, \emph{ids\_inpath}, \emph{indices\_inpath}}{}
Bases: \code{threading.Thread}

Master thread class. The master thread loads all necessary data into suitable data structures and distributes
them among all worker threads.
\index{prepare() (MappingMasterThread method)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.MappingMasterThread.prepare}\pysiglinewithargsret{\bfcode{prepare}}{}{}
Loads The master thread loads all necessary data into suitable data structures. To be more specific,
word embeddings, sentence IDs and word indices are processed.

\end{fulllineitems}

\index{read\_ids\_file() (MappingMasterThread method)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.MappingMasterThread.read_ids_file}\pysiglinewithargsret{\bfcode{read\_ids\_file}}{\emph{ids\_inpath}}{}
Read the sentence ID file.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{ids\_inpath}} (\emph{\texttt{str}}) -- 
Path to sentence IDs file. The file should be in the following \titleref{YAML}-format:
- \textless{}word\textgreater{}:
\begin{quote}
\begin{itemize}
\item {} 
\textless{}sentence id\textgreater{}

\item {} 
\textless{}sentence id\textgreater{}

\end{itemize}

...
\end{quote}


\item[{Returns}] \leavevmode
Dictionary with words as keys and the IDs of the sentences they occur in in a set as value.

\item[{Return type}] \leavevmode
defaultdict

\end{description}\end{quote}

\end{fulllineitems}

\index{start\_threads() (MappingMasterThread method)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.MappingMasterThread.start_threads}\pysiglinewithargsret{\bfcode{start\_threads}}{}{}
Starts all the threads (and ends them if they're all finished).

\end{fulllineitems}


\end{fulllineitems}

\index{MappingWorkerThread (class in src.mapping.mapthreading)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.MappingWorkerThread}\pysiglinewithargsret{\strong{class }\bfcode{MappingWorkerThread}}{\emph{worker\_id}, \emph{vector\_dict}, \emph{vector\_queue}, \emph{vector\_outpath}, \emph{features}, \emph{occurrences}, \emph{indices}, \emph{lambda\_}}{}
Bases: \code{threading.Thread}

Worker thread class. The worker threads do all the dirty work after they receive all necessary data from the master
thread an try to calculate every possible combinations of two word embeddings in a dataset.

All the word embeddings will be stores in a dictionary ({\hyperref[src.mapping:src.mapping.mapthreading.VectorDict]{\crossref{\code{VectorDict}}}} as well as a \code{Queue}).
An idle thread picks a new vector from the queue and then starts to iterate over all the vectors in the
{\hyperref[src.mapping:src.mapping.mapthreading.VectorDict]{\crossref{\code{VectorDict}}}} (this way, the queue gets shorter over time while the size of the dictionary stays fixed).

Before it starts calculations, it checks a) if the co-occurrence constraint is satisfied and b) if this combination
of word embeddings has already been processed.
\index{cosine\_similarity() (MappingWorkerThread method)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.MappingWorkerThread.cosine_similarity}\pysiglinewithargsret{\bfcode{cosine\_similarity}}{\emph{v1}, \emph{v2}}{}
Calculates the cosine similarity (\(cos(\vec{v}_1, \vec{v}_2) \in [-1,-1]\)) between two vectors.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{v1}} (\emph{\texttt{numpy.array}}) -- First vector

\item {} 
\textbf{\texttt{v2}} (\emph{\texttt{numpy.array}}) -- Second vector

\end{itemize}

\item[{Returns}] \leavevmode
Cosine similarity between the two vectors.

\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}

\index{distance() (MappingWorkerThread method)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.MappingWorkerThread.distance}\pysiglinewithargsret{\bfcode{distance}}{\emph{v1}, \emph{v2}}{}
Return the vector offset of two vectors:
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{v1}} (\emph{\texttt{numpy.array}}) -- First vector

\item {} 
\textbf{\texttt{v2}} (\emph{\texttt{numpy.array}}) -- Second vector

\end{itemize}

\end{description}\end{quote}
\begin{description}
\item[{Returns}] \leavevmode
numpy.array: Vector offset.

\end{description}

\end{fulllineitems}

\index{euclidean\_distance1() (MappingWorkerThread method)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.MappingWorkerThread.euclidean_distance1}\pysiglinewithargsret{\bfcode{euclidean\_distance1}}{\emph{v1}, \emph{v2}}{}
Return the euclidean distance between two vectors.
\begin{equation*}
\begin{split}eucl(\vec{a}, \vec{b}) = \sqrt{\sum_{i=1}^n (\vec{b}_i - \vec{a}_i)^2}\end{split}
\end{equation*}\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{v1}} (\emph{\texttt{numpy.array}}) -- First vector

\item {} 
\textbf{\texttt{v2}} (\emph{\texttt{numpy.array}}) -- Second vector

\end{itemize}

\item[{Returns}] \leavevmode
Euclidean distance between the two vectors.

\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}

\index{euclidean\_distance2() (MappingWorkerThread method)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.MappingWorkerThread.euclidean_distance2}\pysiglinewithargsret{\bfcode{euclidean\_distance2}}{\emph{v1}, \emph{v2}}{}
Returns the squared euclidean distance between two vectors.
\begin{equation*}
\begin{split}eucl2(\vec{a}, \vec{b}) = \sum_{i=1}^n (\vec{b}_i - \vec{a}_i)^2\end{split}
\end{equation*}\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{v1}} (\emph{\texttt{numpy.array}}) -- First vector

\item {} 
\textbf{\texttt{v2}} (\emph{\texttt{numpy.array}}) -- Second vector

\end{itemize}

\item[{Returns}] \leavevmode
Squared euclidean distance between the two vectors.

\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}

\index{hash\_indices() (MappingWorkerThread method)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.MappingWorkerThread.hash_indices}\pysiglinewithargsret{\bfcode{hash\_indices}}{\emph{i1}, \emph{i2}}{}
Combines two vector indices (the indices of the words' embeddings used in vector operations) into a hash
s.t. threads can do an easy lookup if a mapping vector has already been calculated.
To guarantee this, \(h(i_1, i_2) = h(i_2, i_1)\) has to be the case.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{i1}} (\emph{\texttt{int}}) -- Index of first word's embedding

\item {} 
\textbf{\texttt{i2}} (\emph{\texttt{int}}) -- Index of second word's embedding

\end{itemize}

\item[{Returns}] \leavevmode
Unique hash for index pair.

\item[{Return type}] \leavevmode
int

\end{description}\end{quote}

\end{fulllineitems}

\index{manhattan\_distance() (MappingWorkerThread method)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.MappingWorkerThread.manhattan_distance}\pysiglinewithargsret{\bfcode{manhattan\_distance}}{\emph{v1}, \emph{v2}}{}
Returns the manhattan distance between two vectors.
\begin{equation*}
\begin{split}manhattan(\vec{a}, \vec{b}) = \sum_{i=1}^n |\vec{b}_i - \vec{a}_i |\end{split}
\end{equation*}\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{v1}} (\emph{\texttt{numpy.array}}) -- First vector

\item {} 
\textbf{\texttt{v2}} (\emph{\texttt{numpy.array}}) -- Second vector

\end{itemize}

\item[{Returns}] \leavevmode
Manhattan distance between the two vectors.

\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}

\index{run() (MappingWorkerThread method)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.MappingWorkerThread.run}\pysiglinewithargsret{\bfcode{run}}{}{}
Starts a worker thread.

\end{fulllineitems}

\index{soft\_cosine\_similarity() (MappingWorkerThread method)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.MappingWorkerThread.soft_cosine_similarity}\pysiglinewithargsret{\bfcode{soft\_cosine\_similarity}}{\emph{v1}, \emph{v2}}{}
Calculates the soft cosine similarity between two vectors.
\begin{align*}\!\begin{aligned}
S = \begin{bmatrix}
        eucl(\vec{a}_1, \vec{b}_1) & \ldots & eucl(\vec{a}_1, \vec{b}_n) \\
        \vdots & \ddots & \vdots \\
        eucl(\vec{a}_n, \vec{b}_1) & \ldots & eucl(\vec{a}_n, \vec{b}_n) \\
\end{bmatrix}\\
softcos(\vec{a}, \vec{b}) = \frac{\sum_{i,j}^N S_{ij}\vec{a}_i\vec{b}_j}{\sqrt{\sum_{i,
j}^N S_{ij}\vec{a}_i\vec{a}_j}\sqrt{\sum_{i,j}^N S_{ij}\vec{b}_i\vec{b}_j}}\\
\end{aligned}\end{align*}
(It considers the similarity between pairs of features.)
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{v1}} (\emph{\texttt{numpy.array}}) -- First vector

\item {} 
\textbf{\texttt{v2}} (\emph{\texttt{numpy.array}}) -- Second vector

\end{itemize}

\item[{Returns}] \leavevmode
Soft cosine similarity between the two vectors.

\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{VectorDict (class in src.mapping.mapthreading)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.VectorDict}\pysigline{\strong{class }\bfcode{VectorDict}}
Bases: \code{object}
\begin{description}
\item[{VectorDict class that serves two functions:}] \leavevmode
\begin{DUlineblock}{0em}
\item[] 1.) Storing word embeddings so they don't allocate memory for every worker thread
\item[] 2.) Providing a set, where are processed vector pairs are stored so no redundant computations are made.
\end{DUlineblock}

\end{description}

Locks are used for synchronization purposes.
\index{add\_skippable() (VectorDict method)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.VectorDict.add_skippable}\pysiglinewithargsret{\bfcode{add\_skippable}}{\emph{index\_hash}}{}
Add the hash of an index pair to a set of already processed vector pairs.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{index\_hash}} (\emph{\texttt{int}}) -- Hash value of index pair. Produced with \code{hash\_indices()}.

\end{description}\end{quote}

\end{fulllineitems}

\index{add\_vector() (VectorDict method)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.VectorDict.add_vector}\pysiglinewithargsret{\bfcode{add\_vector}}{\emph{index}, \emph{vector}}{}
Add a new word embedding.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{index}} (\emph{\texttt{int}}) -- Index of the word the embedding belongs to.

\item {} 
\textbf{\texttt{vector}} (\emph{\texttt{numpy.array}}) -- Word embedding corresponding to given index.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_keys() (VectorDict method)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.VectorDict.get_keys}\pysiglinewithargsret{\bfcode{get\_keys}}{}{}
Get all the keys (word embedding IDs) of this dictionary.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
List of word embedding IDs.

\item[{Return type}] \leavevmode
list

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_vector() (VectorDict method)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.VectorDict.get_vector}\pysiglinewithargsret{\bfcode{get\_vector}}{\emph{index}}{}
Get a word embedding given its word's index.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{index}} (\emph{\texttt{int}}) -- Index of the word the embedding belongs to.

\item[{Returns}] \leavevmode
Word embedding corresponding to given index.

\item[{Return type}] \leavevmode
numpy.array

\end{description}\end{quote}

\end{fulllineitems}

\index{skippable() (VectorDict method)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.VectorDict.skippable}\pysiglinewithargsret{\bfcode{skippable}}{\emph{index\_hash}}{}
Checks whether a pair of vectors has already been processed.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{index\_hash}} (\emph{\texttt{int}}) -- Hash value of index pair. Produced with \code{hash\_indices()}.

\item[{Returns}] \leavevmode
Whether a pair of vectors has already been processed.

\item[{Return type}] \leavevmode
bool

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{alt() (in module src.mapping.mapthreading)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.alt}\pysiglinewithargsret{\bfcode{alt}}{\emph{func}}{}
Prepends the local time to the output of a function.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{func}} (\emph{\texttt{function}}) -- Function the local time should be prepended to.

\end{description}\end{quote}

\end{fulllineitems}

\index{init\_argparse() (in module src.mapping.mapthreading)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.init_argparse}\pysiglinewithargsret{\bfcode{init\_argparse}}{}{}
Initialize all possible arguments for the argument parser.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
ArgumentParser object with command line arguments for this script.

\item[{Return type}] \leavevmode
\code{argparse.ArgumentParser}

\end{description}\end{quote}

\end{fulllineitems}

\index{main() (in module src.mapping.mapthreading)}

\begin{fulllineitems}
\phantomsection\label{src.mapping:src.mapping.mapthreading.main}\pysiglinewithargsret{\bfcode{main}}{}{}
Main function that initializes the master thread with command line arguments and starts it.

\end{fulllineitems}



\paragraph{Module contents}
\label{src.mapping:module-src.mapping}\label{src.mapping:module-contents}\index{src.mapping (module)}

\subsubsection{src.misc package}
\label{src.misc:src-misc-package}\label{src.misc::doc}

\paragraph{Submodules}
\label{src.misc:submodules}

\paragraph{src.misc.decorators module}
\label{src.misc:module-src.misc.decorators}\label{src.misc:src-misc-decorators-module}\index{src.misc.decorators (module)}
This module contains decorators that wrap around functions used in other modules.
\index{log\_time() (in module src.misc.decorators)}

\begin{fulllineitems}
\phantomsection\label{src.misc:src.misc.decorators.log_time}\pysiglinewithargsret{\bfcode{log\_time}}{\emph{logpath='log.txt'}, \emph{interval=5}}{}
This decorator is used to log the execution time of a function into a given logfile, following a constant interval.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{logpath}} (\emph{\texttt{str}}) -- Path to logfile.

\item {} 
\textbf{\texttt{interval}} (\emph{\texttt{int}}) -- Logging interval in seconds.

\end{itemize}

\item[{Returns}] \leavevmode
Decorator with function.

\item[{Return type}] \leavevmode
function

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{src.misc.helpers module}
\label{src.misc:src-misc-helpers-module}\label{src.misc:module-src.misc.helpers}\index{src.misc.helpers (module)}
This module contains decorators that wrap aroud functions used in other modules.
\index{alt() (in module src.misc.helpers)}

\begin{fulllineitems}
\phantomsection\label{src.misc:src.misc.helpers.alt}\pysiglinewithargsret{\bfcode{alt}}{\emph{func}}{}
Prepends the local time to the output of a function.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{func}} (\emph{\texttt{function}}) -- Function the local time should be prepended to.

\end{description}\end{quote}

\end{fulllineitems}

\index{capitalize() (in module src.misc.helpers)}

\begin{fulllineitems}
\phantomsection\label{src.misc:src.misc.helpers.capitalize}\pysiglinewithargsret{\bfcode{capitalize}}{\emph{word}}{}
Capitalizes a string.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{word}} (\emph{\texttt{str}}) -- Word to be capitalized.

\item[{Returns}] \leavevmode
Capitalized word.

\item[{Return type}] \leavevmode
str

\end{description}\end{quote}

\end{fulllineitems}

\index{contains\_tag() (in module src.misc.helpers)}

\begin{fulllineitems}
\phantomsection\label{src.misc:src.misc.helpers.contains_tag}\pysiglinewithargsret{\bfcode{contains\_tag}}{\emph{line}}{}
Checks whether the current line contains an xml tag.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{line}} (\emph{\texttt{str}}) -- Current line

\item[{Returns}] \leavevmode
Whether the current line contains an xml tag.

\item[{Return type}] \leavevmode
bool

\end{description}\end{quote}

\end{fulllineitems}

\index{extract\_sentence\_id() (in module src.misc.helpers)}

\begin{fulllineitems}
\phantomsection\label{src.misc:src.misc.helpers.extract_sentence_id}\pysiglinewithargsret{\bfcode{extract\_sentence\_id}}{\emph{tag}}{}
Extract the sentence ID of current sentence.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{tag}} (\emph{\texttt{str}}) -- Sentence tag

\item[{Returns}] \leavevmode
sentence ID

\item[{Return type}] \leavevmode
str

\end{description}\end{quote}

\end{fulllineitems}

\index{format\_fbid() (in module src.misc.helpers)}

\begin{fulllineitems}
\phantomsection\label{src.misc:src.misc.helpers.format_fbid}\pysiglinewithargsret{\bfcode{format\_fbid}}{\emph{fbid}}{}
Transform the format of the \emph{Freebase} IDs from the format used in the dataset to the format used in requests.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{fbid}} (\emph{\texttt{str}}) -- \emph{Freebase} ID to be formatted.

\item[{Returns}] \leavevmode
Formatted \emph{Freebase} ID.

\item[{Return type}] \leavevmode
str

\end{description}\end{quote}

\end{fulllineitems}

\index{load\_vectors() (in module src.misc.helpers)}

\begin{fulllineitems}
\phantomsection\label{src.misc:src.misc.helpers.load_vectors}\pysiglinewithargsret{\bfcode{load\_vectors}}{\emph{vector\_inpath}}{}
Load word embeddings, gensim style.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{vector\_inpath}} (\emph{\texttt{str}}) -- Path to vector file.

\item[{Returns}] \leavevmode
Word2Vec gensim model.

\item[{Return type}] \leavevmode
gensim.models.Word2Vec

\end{description}\end{quote}

\end{fulllineitems}

\index{load\_vectors\_from\_model() (in module src.misc.helpers)}

\begin{fulllineitems}
\phantomsection\label{src.misc:src.misc.helpers.load_vectors_from_model}\pysiglinewithargsret{\bfcode{load\_vectors\_from\_model}}{\emph{vector\_inpath}, \emph{max\_n=None}, \emph{indices=False}}{}
Load word embeddings (or mapping vectors), my style.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{vector\_inpath}} (\emph{\texttt{str}}) -- Path to vector file.

\item {} 
\textbf{\texttt{max\_n}} (\emph{\texttt{int}}) -- Maximum number of vectors to load.

\item {} 
\textbf{\texttt{indices}} (\emph{\texttt{bool}}) -- Flag to indicate the loading of mapping vectors.

\end{itemize}

\item[{Returns}] \leavevmode
A list of words as well as a dictionary with the vectors as numpy.arrays as value and their
corresponding words or index pairs as keys.

\item[{Return type}] \leavevmode
Tuple

\end{description}\end{quote}

\end{fulllineitems}

\index{partitions\_list() (in module src.misc.helpers)}

\begin{fulllineitems}
\phantomsection\label{src.misc:src.misc.helpers.partitions_list}\pysiglinewithargsret{\bfcode{partitions\_list}}{\emph{l}, \emph{prts}}{}
Partitions a list into three parts according to their percentages in regard to the length of the original list given
in a tuple as floats.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{l}} (\emph{\texttt{list}}) -- List to be partitioned.

\item {} 
\textbf{\texttt{prts}} (\emph{\texttt{tuple}}) -- Tuple of float with new list sizes.

\end{itemize}

\item[{Returns}] \leavevmode
Tuple of the three new lists.

\item[{Return type}] \leavevmode
tuple

\end{description}\end{quote}

\end{fulllineitems}

\index{read\_dataset() (in module src.misc.helpers)}

\begin{fulllineitems}
\phantomsection\label{src.misc:src.misc.helpers.read_dataset}\pysiglinewithargsret{\bfcode{read\_dataset}}{\emph{inpath}}{}
Reads a generic dataset with rows separated by tabs into a list.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{inpath}} (\emph{\texttt{str}}) -- Path to dataset.

\item[{Returns}] \leavevmode
List of line contents as tuples.

\item[{Return type}] \leavevmode
list

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{Module contents}
\label{src.misc:module-contents}\label{src.misc:module-src.misc}\index{src.misc (module)}

\subsubsection{src.prep package}
\label{src.prep::doc}\label{src.prep:src-prep-package}\begin{description}
\item[{This package contains subpackages dedicated to different preparations steps for fundamental resources:}] \leavevmode\begin{itemize}
\item {} 
\code{src.prep.corpus} contains scripts for the preprocessing of the \code{DECOW14X} corpus.

\item {} 
\code{src.prep.nes} contains scripts to extract \emph{Named Entities} and other information about them from the corpus.

\item {} 
\code{src.prep.relations} contains scripts related to the \code{FB14k} relation datatset.

\end{itemize}

\end{description}


\paragraph{Subpackages}
\label{src.prep:subpackages}

\subparagraph{src.prep.corpus package}
\label{src.prep.corpus::doc}\label{src.prep.corpus:src-prep-corpus-package}

\subparagraph{Submodules}
\label{src.prep.corpus:submodules}

\subparagraph{src.prep.corpus.convert\_to\_plain module}
\label{src.prep.corpus:src-prep-corpus-convert-to-plain-module}\label{src.prep.corpus:module-src.prep.corpus.convert_to_plain}\index{src.prep.corpus.convert\_to\_plain (module)}
Convert the \emph{DECOW14X} corpus into a plain text file. Is used as pre-processing step for the
\href{https://code.google.com/archive/p/word2vec/}{word2vec} training.
To make this this more feasible (decow is a \textbf{huge} corpus), python's \code{multiprocessing} is used, s.t. every
part of the corpus in simultaneously processed. Afterwards, a bash command like \code{cat} can be used to merge into one
single file.
\index{convert\_decow\_to\_plain() (in module src.prep.corpus.convert\_to\_plain)}

\begin{fulllineitems}
\phantomsection\label{src.prep.corpus:src.prep.corpus.convert_to_plain.convert_decow_to_plain}\pysiglinewithargsret{\bfcode{convert\_decow\_to\_plain}}{\emph{decow\_dir}, \emph{out\_dir}, \emph{log\_path}, \emph{merge\_nes}, \emph{log\_interval}}{}
Convert the whole corpus into plain text.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{decow\_dir}} (\emph{\texttt{str}}) -- Path to directory with decow corpus paths.

\item {} 
\textbf{\texttt{out\_dir}} (\emph{\texttt{str}}) -- Path where plain text parts should be written to.

\item {} 
\textbf{\texttt{log\_path}} (\emph{\texttt{str}}) -- Path where the log files should be written to.

\item {} 
\textbf{\texttt{merge\_nes}} (\emph{\texttt{bool}}) -- Flag to indicate whether multi-word expression should be merged with underscores.

\item {} 
\textbf{\texttt{log\_interval}} (\emph{\texttt{int}}) -- Interval to log current process state in seconds.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{convert\_part() (in module src.prep.corpus.convert\_to\_plain)}

\begin{fulllineitems}
\phantomsection\label{src.prep.corpus:src.prep.corpus.convert_to_plain.convert_part}\pysiglinewithargsret{\bfcode{convert\_part}}{\emph{argstuple}}{}
Convert a corpus part into plain text without merging multiple word entries.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{argstuple}} -- Tuple of methods arguments (\code{inpath} (\emph{str}): Path to this processes' corpus part / \code{dir\_outpath}
(\emph{str}): Path to this processes' output / \code{log\_path} (\emph{str}): Path to this processes' log / \code{interval}
(\emph{int}): Logging interval in seconds)

\end{description}\end{quote}

\end{fulllineitems}

\index{convert\_part\_merging() (in module src.prep.corpus.convert\_to\_plain)}

\begin{fulllineitems}
\phantomsection\label{src.prep.corpus:src.prep.corpus.convert_to_plain.convert_part_merging}\pysiglinewithargsret{\bfcode{convert\_part\_merging}}{\emph{argstuple}}{}
Convert a corpus part into plain text and merging multiple word entries.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{argstuple}} -- Tuple of methods arguments (\code{inpath} (\emph{str}): Path to this processes' corpus part / \code{dir\_outpath}
(\emph{str}): Path to this processes' output / \code{log\_path} (\emph{str}): Path to this processes' log / \code{interval}
(\emph{int}): Logging interval in seconds)

\end{description}\end{quote}

\end{fulllineitems}

\index{extract\_named\_entity() (in module src.prep.corpus.convert\_to\_plain)}

\begin{fulllineitems}
\phantomsection\label{src.prep.corpus:src.prep.corpus.convert_to_plain.extract_named_entity}\pysiglinewithargsret{\bfcode{extract\_named\_entity}}{\emph{line}}{}
Extract named entity from current line.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{line}} (\emph{\texttt{str}}) -- Current line

\item[{Returns}] \leavevmode
Extracted named entity or None if no named entity is present.

\item[{Return type}] \leavevmode
str or None

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_file\_number() (in module src.prep.corpus.convert\_to\_plain)}

\begin{fulllineitems}
\phantomsection\label{src.prep.corpus:src.prep.corpus.convert_to_plain.get_file_number}\pysiglinewithargsret{\bfcode{get\_file\_number}}{\emph{filename}}{}
Get the number of the current decow corpus part.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{filename}} (\emph{\texttt{str}}) -- Decow corpus part file name

\item[{Returns}] \leavevmode
File number

\item[{Return type}] \leavevmode
str

\end{description}\end{quote}

\end{fulllineitems}

\index{main() (in module src.prep.corpus.convert\_to\_plain)}

\begin{fulllineitems}
\phantomsection\label{src.prep.corpus:src.prep.corpus.convert_to_plain.main}\pysiglinewithargsret{\bfcode{main}}{}{}
Main function. Uses command lines to start corpus processing.

\end{fulllineitems}



\subparagraph{src.prep.corpus.extract\_conll module}
\label{src.prep.corpus:src-prep-corpus-extract-conll-module}\label{src.prep.corpus:module-src.prep.corpus.extract_conll}\index{src.prep.corpus.extract\_conll (module)}
This script can be used to extract information out of a specific column of a file in the
\href{http://ilk.uvt.nl/conll/}{CoNLL}-format.
\index{extract\_conll() (in module src.prep.corpus.extract\_conll)}

\begin{fulllineitems}
\phantomsection\label{src.prep.corpus:src.prep.corpus.extract_conll.extract_conll}\pysiglinewithargsret{\bfcode{extract\_conll}}{\emph{inpath}, \emph{outpath}, \emph{column}}{}
Extract information out of CoNLL files.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{inpath}} (\emph{\texttt{str}}) -- Path to input file.

\item {} 
\textbf{\texttt{outpath}} (\emph{\texttt{str}}) -- Path to output file.

\item {} 
\textbf{\texttt{column}} (\emph{\texttt{int}}) -- The number (-1) of the column the information should be extracted from.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{init\_argparse() (in module src.prep.corpus.extract\_conll)}

\begin{fulllineitems}
\phantomsection\label{src.prep.corpus:src.prep.corpus.extract_conll.init_argparse}\pysiglinewithargsret{\bfcode{init\_argparse}}{}{}
Initialize all possible arguments for the argument parser.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
ArgumentParser object with command line arguments for this script.

\item[{Return type}] \leavevmode
\code{argparse.ArgumentParser}

\end{description}\end{quote}

\end{fulllineitems}

\index{main() (in module src.prep.corpus.extract\_conll)}

\begin{fulllineitems}
\phantomsection\label{src.prep.corpus:src.prep.corpus.extract_conll.main}\pysiglinewithargsret{\bfcode{main}}{}{}
The main function.

\end{fulllineitems}



\subparagraph{src.prep.corpus.mapper module}
\label{src.prep.corpus:module-src.prep.corpus.mapper}\label{src.prep.corpus:src-prep-corpus-mapper-module}\index{src.prep.corpus.mapper (module)}
Mapper classed used to count frequencies of words in a corpus. Corpus has to be in plain text format. This class is
used in a \href{https://en.wikipedia.org/wiki/MapReduce}{Map-Reduce}-pattern, so you also need the \code{reducer.py} class.

Then, you can open your terminal and pipe them together:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}} cat corpus.txt \PYG{p}{\textbar{}} ./mapper.py \PYG{p}{\textbar{}} sort \PYG{p}{\textbar{}} ./reducer.py
\end{Verbatim}

Also, you probably have to remove the \code{if \_\_name\_\_ == "\_\_main\_\_":} line and unindent the remaining code,
this is only
due to sphinx being picky and not documenting plain python scripts at all.


\subparagraph{src.prep.corpus.reducer module}
\label{src.prep.corpus:module-src.prep.corpus.reducer}\label{src.prep.corpus:src-prep-corpus-reducer-module}\index{src.prep.corpus.reducer (module)}
Reducer classed used to count frequencies of words in a corpus. Corpus has to be in plain text format. This class is
used in a \href{https://en.wikipedia.org/wiki/MapReduce}{Map-Reduce}-pattern, so you also need the \code{mapper.py} class.

Then, you can open your terminal and pipe them together:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}} cat corpus.txt \PYG{p}{\textbar{}} ./mapper.py \PYG{p}{\textbar{}} sort \PYG{p}{\textbar{}} ./reducer.py
\end{Verbatim}

Also, you probably have to remove the \code{if \_\_name\_\_ == "\_\_main\_\_":} line and unindent the remaining code,
this is only
due to sphinx being picky and not documenting plain python scripts at all.


\subparagraph{Module contents}
\label{src.prep.corpus:module-contents}\label{src.prep.corpus:module-src.prep.corpus}\index{src.prep.corpus (module)}

\subparagraph{src.prep.nes package}
\label{src.prep.nes:src-prep-nes-package}\label{src.prep.nes::doc}

\subparagraph{Submodules}
\label{src.prep.nes:submodules}

\subparagraph{src.prep.nes.extract\_nes module}
\label{src.prep.nes:src-prep-nes-extract-nes-module}\label{src.prep.nes:module-src.prep.nes.extract_nes}\index{src.prep.nes.extract\_nes (module)}
This script is used to find all named entities in a corpus, extract them and also store their frequencies as well as
the IDs of the sentences they occur in.
\index{extract\_named\_entity() (in module src.prep.nes.extract\_nes)}

\begin{fulllineitems}
\phantomsection\label{src.prep.nes:src.prep.nes.extract_nes.extract_named_entity}\pysiglinewithargsret{\bfcode{extract\_named\_entity}}{\emph{line}}{}
Extracts named entity from current line if present.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{line}} (\emph{\texttt{str}}) -- Current line

\item[{Returns}] \leavevmode
Named entity in this line and its NE tag

\item[{Return type}] \leavevmode
tuple

\end{description}\end{quote}

\end{fulllineitems}

\index{main() (in module src.prep.nes.extract\_nes)}

\begin{fulllineitems}
\phantomsection\label{src.prep.nes:src.prep.nes.extract_nes.main}\pysiglinewithargsret{\bfcode{main}}{}{}
Main function.

\end{fulllineitems}

\index{process() (in module src.prep.nes.extract\_nes)}

\begin{fulllineitems}
\phantomsection\label{src.prep.nes:src.prep.nes.extract_nes.process}\pysiglinewithargsret{\bfcode{process}}{\emph{inpath}, \emph{outpath}, \emph{logpath}}{}
Starts extracting named entities and their corresponding sentence IDs.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{inpath}} (\emph{\texttt{str}}) -- Path to input file. Input file is a gzipped xml file.

\item {} 
\textbf{\texttt{outpath}} (\emph{\texttt{str}}) -- Path to output directory.

\item {} 
\textbf{\texttt{logpath}} (\emph{\texttt{str}}) -- Path to log directory.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{write\_dict\_into\_file() (in module src.prep.nes.extract\_nes)}

\begin{fulllineitems}
\phantomsection\label{src.prep.nes:src.prep.nes.extract_nes.write_dict_into_file}\pysiglinewithargsret{\bfcode{write\_dict\_into\_file}}{\emph{dictionary}, \emph{out\_path}}{}
Write a dictionary of named entities, their tags and their frequencies into a file.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{dictionary}} (\emph{\texttt{dict}}) -- Dictionary with named entities as key and their frequencies as values.

\item {} 
\textbf{\texttt{out\_path}} (\emph{\texttt{str}}) -- Path the frequencies should written to.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{write\_ids\_into\_file() (in module src.prep.nes.extract\_nes)}

\begin{fulllineitems}
\phantomsection\label{src.prep.nes:src.prep.nes.extract_nes.write_ids_into_file}\pysiglinewithargsret{\bfcode{write\_ids\_into\_file}}{\emph{dictionary}, \emph{out\_path}}{}
Write a dictionary of named entities,, their tags and IDs of the sentences they occur in into a file.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{dictionary}} (\emph{\texttt{dict}}) -- Dictionary with named entities as key and their occurrences as a list as values.

\item {} 
\textbf{\texttt{out\_path}} (\emph{\texttt{str}}) -- Path the frequencies should written to.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subparagraph{src.prep.nes.merge module}
\label{src.prep.nes:src-prep-nes-merge-module}\label{src.prep.nes:module-src.prep.nes.merge}\index{src.prep.nes.merge (module)}
This module is used to merge various output files created from \code{extract\_nes.py}. Because they are only created
for one corpus part at a time, you end up with multiple files that cannot simply by concatenated. Therefore, this module
aims to merge them in a (relatively) memory-efficient manner.
\index{freq\_worker() (in module src.prep.nes.merge)}

\begin{fulllineitems}
\phantomsection\label{src.prep.nes:src.prep.nes.merge.freq_worker}\pysiglinewithargsret{\bfcode{freq\_worker}}{\emph{inpath}}{}
Reads the named entity frequencies from a file.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{inpath}} (\emph{\texttt{str}}) -- Path to frequency file.

\item[{Returns}] \leavevmode
Dictionary with named entities as keys and their frequencies as values.

\item[{Return type}] \leavevmode
dict

\end{description}\end{quote}

\end{fulllineitems}

\index{id\_worker() (in module src.prep.nes.merge)}

\begin{fulllineitems}
\phantomsection\label{src.prep.nes:src.prep.nes.merge.id_worker}\pysiglinewithargsret{\bfcode{id\_worker}}{\emph{inpath}}{}
Reads the named entity ids from a file.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{inpath}} (\emph{\texttt{str}}) -- Path to frequency file.

\item[{Returns}] \leavevmode
Dictionary with named entities as keys and their ids as values.

\item[{Return type}] \leavevmode
dict

\end{description}\end{quote}

\end{fulllineitems}

\index{main() (in module src.prep.nes.merge)}

\begin{fulllineitems}
\phantomsection\label{src.prep.nes:src.prep.nes.merge.main}\pysiglinewithargsret{\bfcode{main}}{}{}
Main function, handling command line arguments.

\end{fulllineitems}

\index{merge\_dicts() (in module src.prep.nes.merge)}

\begin{fulllineitems}
\phantomsection\label{src.prep.nes:src.prep.nes.merge.merge_dicts}\pysiglinewithargsret{\bfcode{merge\_dicts}}{\emph{dicttuple}}{}
Merges two dictionary (efficiently).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{dicttuple}} (\emph{\texttt{tuple}}) -- Tuple of two frequency dictionaries.

\item[{Returns}] \leavevmode
New merged dictionary

\item[{Return type}] \leavevmode
dict

\end{description}\end{quote}

\end{fulllineitems}

\index{merge\_frequency\_files() (in module src.prep.nes.merge)}

\begin{fulllineitems}
\phantomsection\label{src.prep.nes:src.prep.nes.merge.merge_frequency_files}\pysiglinewithargsret{\bfcode{merge\_frequency\_files}}{\emph{infiles\_path}, \emph{outpath}, \emph{logpath}}{}
Merge multiple named entitiy frequency files.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{infiles\_path}} (\emph{\texttt{str}}) -- Path to input file directory.

\item {} 
\textbf{\texttt{outpath}} (\emph{\texttt{str}}) -- Path to output directory.

\item {} 
\textbf{\texttt{logpath}} (\emph{\texttt{str}}) -- Path to logging directory.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{merge\_id\_dicts() (in module src.prep.nes.merge)}

\begin{fulllineitems}
\phantomsection\label{src.prep.nes:src.prep.nes.merge.merge_id_dicts}\pysiglinewithargsret{\bfcode{merge\_id\_dicts}}{\emph{dicttuple}}{}
Merges two id dictionary (efficiently).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{dicttuple}} (\emph{\texttt{tuple}}) -- Tuple of two id dictionaries.

\item[{Returns}] \leavevmode
New merged dictionary

\item[{Return type}] \leavevmode
dict

\end{description}\end{quote}

\end{fulllineitems}

\index{merge\_id\_files() (in module src.prep.nes.merge)}

\begin{fulllineitems}
\phantomsection\label{src.prep.nes:src.prep.nes.merge.merge_id_files}\pysiglinewithargsret{\bfcode{merge\_id\_files}}{\emph{infiles\_path}, \emph{outpath}, \emph{logpath}, \emph{yaml=False}}{}
Merge multiple named entitiy id files.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{infiles\_path}} (\emph{\texttt{str}}) -- Path to input file directory.

\item {} 
\textbf{\texttt{outpath}} (\emph{\texttt{str}}) -- Path to output directory.

\item {} 
\textbf{\texttt{logpath}} (\emph{\texttt{str}}) -- Path to logging directory.

\item {} 
\textbf{\texttt{yaml}} (\emph{\texttt{bool}}) -- Flag to indicate whether merged files should be written in yaml format.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{rl() (in module src.prep.nes.merge)}

\begin{fulllineitems}
\phantomsection\label{src.prep.nes:src.prep.nes.merge.rl}\pysiglinewithargsret{\bfcode{rl}}{\emph{infile}}{}
Lazy function to read a line from a while and remove redundant whitespaces.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{infile}} (\emph{\texttt{str}}) -- Path to input file.

\item[{Returns}] \leavevmode
Stripped line

\item[{Return type}] \leavevmode
str

\end{description}\end{quote}

\end{fulllineitems}



\subparagraph{src.prep.nes.statistics module}
\label{src.prep.nes:src-prep-nes-statistics-module}\label{src.prep.nes:module-src.prep.nes.statistics}\index{src.prep.nes.statistics (module)}
This script collects a few statistics about named entities extracted from the corpus and the percentage of their
occurrence in the \emph{Freebase} relation dataset.
Requires a relation file in yaml format and a merged named entity frequency file, see \code{extract\_nes.py},
\code{merge.py} and  \code{relations.py}.
\index{calculate\_occurrences() (in module src.prep.nes.statistics)}

\begin{fulllineitems}
\phantomsection\label{src.prep.nes:src.prep.nes.statistics.calculate_occurrences}\pysiglinewithargsret{\bfcode{calculate\_occurrences}}{\emph{freqpath}, \emph{relations\_path}}{}
Calculate statistics about named entities extracted from the corpus and the percentage of their
occurrence in the \emph{Freebase} relation dataset.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{freqpath}} (\emph{\texttt{str}}) -- Path to merged frequencies file.

\item {} 
\textbf{\texttt{relations\_path}} (\emph{\texttt{str}}) -- Path to relation yaml file.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{main() (in module src.prep.nes.statistics)}

\begin{fulllineitems}
\phantomsection\label{src.prep.nes:src.prep.nes.statistics.main}\pysiglinewithargsret{\bfcode{main}}{}{}
Main function

\end{fulllineitems}



\subparagraph{Module contents}
\label{src.prep.nes:module-src.prep.nes}\label{src.prep.nes:module-contents}\index{src.prep.nes (module)}

\subparagraph{src.prep.relations package}
\label{src.prep.relations:src-prep-relations-package}\label{src.prep.relations::doc}

\subparagraph{Submodules}
\label{src.prep.relations:submodules}

\subparagraph{src.prep.relations.relations module}
\label{src.prep.relations:src-prep-relations-relations-module}\label{src.prep.relations:module-src.prep.relations.relations}\index{src.prep.relations.relations (module)}
This modules is about retrieving the names of entities and relations in the
\href{https://everest.hds.utc.fr/doku.php?id=en:smemlj12}{FB15k dataset}. Because the entities are
used with their (quite cryptic) \emph{Freebase} ids, those have to be resolved.

\begin{notice}{warning}{Warning:}
Unfortunately, it isn't possible anymore to use this code (July 2016), because the \emph{Freebase API} is now
deprecated; the whole \emph{Freebase} project has been integrated into \emph{Wikidata}. However, this code is still
included to show the process of thow freebase where transformed into real names using the API and the MQL query
language.
\end{notice}
\index{MissingTranslationException}

\begin{fulllineitems}
\phantomsection\label{src.prep.relations:src.prep.relations.relations.MissingTranslationException}\pysigline{\strong{exception }\bfcode{MissingTranslationException}}
Bases: \code{exceptions.Exception}

Exception class to be thrown in cases where the API cannot find a translation for a \emph{Freebase} API given the
target language.
\index{get\_id() (MissingTranslationException method)}

\begin{fulllineitems}
\phantomsection\label{src.prep.relations:src.prep.relations.relations.MissingTranslationException.get_id}\pysiglinewithargsret{\bfcode{get\_id}}{}{}
Return the \emph{Freebase} ID that triggered this exception.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
\emph{Freebase} ID that triggered this exception.

\item[{Return type}] \leavevmode
str

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{fetch\_name() (in module src.prep.relations.relations)}

\begin{fulllineitems}
\phantomsection\label{src.prep.relations:src.prep.relations.relations.fetch_name}\pysiglinewithargsret{\bfcode{fetch\_name}}{\emph{fbid}, \emph{lang='de'}}{}
Looks for the translation of a \emph{Freebase} id in a target language.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{fbid}} (\emph{\texttt{str}}) -- Freebase ID to be translated

\item {} 
\textbf{\texttt{lang}} (\emph{\texttt{str}}) -- Target language of the translation process (default is ``de'' for german).

\end{itemize}

\item[{Raises}] \leavevmode
{\hyperref[src.prep.relations:src.prep.relations.relations.MissingTranslationException]{\crossref{\code{MissingTranslationException}}}} -- If no translation is found.

\item[{Returns}] \leavevmode
Translation of \emph{Freebase} ID

\item[{Return type}] \leavevmode
str

\end{description}\end{quote}

\end{fulllineitems}

\index{fetch\_relation\_triples\_of\_file() (in module src.prep.relations.relations)}

\begin{fulllineitems}
\phantomsection\label{src.prep.relations:src.prep.relations.relations.fetch_relation_triples_of_file}\pysiglinewithargsret{\bfcode{fetch\_relation\_triples\_of\_file}}{\emph{inpath}, \emph{outpath}, \emph{logpath}, \emph{lang='de'}}{}
Start the translation of the \emph{Freebase} IDs into real names.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{inpath}} (\emph{\texttt{str}}) -- Path to \emph{Freebase} relation file.

\item {} 
\textbf{\texttt{outpath}} (\emph{\texttt{str}}) -- Path the translated triplets should be written to.

\item {} 
\textbf{\texttt{logpath}} (\emph{\texttt{str}}) -- Path to log file.

\item {} 
\textbf{\texttt{lang}} (\emph{\texttt{str}}) -- Target language of the translation process (default is ``de'' for german).

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{freebase\_request() (in module src.prep.relations.relations)}

\begin{fulllineitems}
\phantomsection\label{src.prep.relations:src.prep.relations.relations.freebase_request}\pysiglinewithargsret{\bfcode{freebase\_request}}{\emph{query}, \emph{api\_key}, \emph{service\_url}}{}
Sends a request to the \emph{Freebase} API.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{query}} (\emph{\texttt{list}}) -- \code{MQL} query as a dictionary wrapped inside a list

\item {} 
\textbf{\texttt{api\_key}} (\emph{\texttt{str}}) -- API key

\item {} 
\textbf{\texttt{service\_url}} (\emph{\texttt{str}}) -- URI to API

\end{itemize}

\item[{Returns}] \leavevmode
Response as a dictionary

\item[{Return type}] \leavevmode
dict

\end{description}\end{quote}

\end{fulllineitems}

\index{init\_optparser() (in module src.prep.relations.relations)}

\begin{fulllineitems}
\phantomsection\label{src.prep.relations:src.prep.relations.relations.init_optparser}\pysiglinewithargsret{\bfcode{init\_optparser}}{}{}
Initialize the option parser for this script.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
OptionParser object

\item[{Return type}] \leavevmode
OptionParser

\end{description}\end{quote}

\end{fulllineitems}

\index{main() (in module src.prep.relations.relations)}

\begin{fulllineitems}
\phantomsection\label{src.prep.relations:src.prep.relations.relations.main}\pysiglinewithargsret{\bfcode{main}}{}{}
Main function. Start translation of relation triplets based on command line arguments.

\end{fulllineitems}

\index{read\_credentials() (in module src.prep.relations.relations)}

\begin{fulllineitems}
\phantomsection\label{src.prep.relations:src.prep.relations.relations.read_credentials}\pysiglinewithargsret{\bfcode{read\_credentials}}{}{}
Reads API credentials from a file.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
API key and API URI as strings

\item[{Return type}] \leavevmode
tuple

\end{description}\end{quote}

\end{fulllineitems}

\index{rl() (in module src.prep.relations.relations)}

\begin{fulllineitems}
\phantomsection\label{src.prep.relations:src.prep.relations.relations.rl}\pysiglinewithargsret{\bfcode{rl}}{\emph{infile}}{}
Lazy function to read a line from a while and remove redundant whitespaces.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{infile}} (\emph{\texttt{str}}) -- Path to input file.

\item[{Returns}] \leavevmode
Stripped line

\item[{Return type}] \leavevmode
str

\end{description}\end{quote}

\end{fulllineitems}



\subparagraph{Module contents}
\label{src.prep.relations:module-src.prep.relations}\label{src.prep.relations:module-contents}\index{src.prep.relations (module)}

\paragraph{Module contents}
\label{src.prep:module-contents}\label{src.prep:module-src.prep}\index{src.prep (module)}

\subsubsection{src.trans\_e package}
\label{src.trans_e:src-trans-e-package}\label{src.trans_e::doc}

\paragraph{src.trans\_e.add\_inverse\_relations module}
\label{src.trans_e:module-src.trans_e.add_inverse_relations}\label{src.trans_e:src-trans-e-add-inverse-relations-module}\index{src.trans\_e.add\_inverse\_relations (module)}
This script is used to add inverse relations to a \emph{Freebase} relations dataset, e.g.
\emph{/location/location/contains} and \emph{/location/location/containedby}.
\index{add\_inverse\_relations() (in module src.trans\_e.add\_inverse\_relations)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.add_inverse_relations.add_inverse_relations}\pysiglinewithargsret{\bfcode{add\_inverse\_relations}}{\emph{relations\_inpath}, \emph{relations\_outpath}, \emph{inverse\_relations}}{}
\end{fulllineitems}

\index{init\_argparse() (in module src.trans\_e.add\_inverse\_relations)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.add_inverse_relations.init_argparse}\pysiglinewithargsret{\bfcode{init\_argparse}}{}{}
Initialize all possible arguments for the argument parser.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
ArgumentParser object with command line arguments for this script.

\item[{Return type}] \leavevmode
\code{argparse.ArgumentParser}

\end{description}\end{quote}

\end{fulllineitems}

\index{main() (in module src.trans\_e.add\_inverse\_relations)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.add_inverse_relations.main}\pysiglinewithargsret{\bfcode{main}}{}{}
The main function. Uses command line arguments to start the script.

\end{fulllineitems}

\index{read\_file\_with\_inverse\_relations() (in module src.trans\_e.add\_inverse\_relations)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.add_inverse_relations.read_file_with_inverse_relations}\pysiglinewithargsret{\bfcode{read\_file\_with\_inverse\_relations}}{\emph{inverse\_inpath}}{}
Read a \emph{Freebase} information file where inverse relations are present and separated by a simple dot.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{inverse\_inpath}} (\emph{\texttt{str}}) -- Path to \emph{Freebase} relation file.

\item[{Returns}] \leavevmode
Dictionary with a relation as a key and its inverse as value.

\item[{Return type}] \leavevmode
defaultdict

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{src.trans\_e.contains\_entities module}
\label{src.trans_e:src-trans-e-contains-entities-module}\label{src.trans_e:module-src.trans_e.contains_entities}\index{src.trans\_e.contains\_entities (module)}
This script analyses entities in the \emph{Freebase} \code{FB14k} relations datatset and the tql wikidata dump.
This is handy because the \emph{Freebase} API is deprecated nowadays. Also, this scripted was used to create the \code{GER14k}
dataset.
\index{contains\_entities() (in module src.trans\_e.contains\_entities)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.contains_entities.contains_entities}\pysiglinewithargsret{\bfcode{contains\_entities}}{\emph{entities1}, \emph{entities2}}{}
Prints stats about two sets of entities.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{entities1}} (\emph{\texttt{set}}) -- First set of entities.

\item {} 
\textbf{\texttt{entities2}} (\emph{\texttt{set}}) -- Second set of entities.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{create\_new\_dataset() (in module src.trans\_e.contains\_entities)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.contains_entities.create_new_dataset}\pysiglinewithargsret{\bfcode{create\_new\_dataset}}{\emph{entities1}, \emph{dataset}, \emph{outpath}}{}
Write a new dataset only with relations which entities appear in a specific set.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{entities1}} (\emph{\texttt{set}}) -- Set entities in relations have to appear in.

\item {} 
\textbf{\texttt{dataset}} (\emph{\texttt{list}}) -- Original dataset (a list of tuples).

\item {} 
\textbf{\texttt{outpath}} (\emph{\texttt{str}}) -- Path to new dataset.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{extract\_entities\_from\_relation\_dataset() (in module src.trans\_e.contains\_entities)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.contains_entities.extract_entities_from_relation_dataset}\pysiglinewithargsret{\bfcode{extract\_entities\_from\_relation\_dataset}}{\emph{dataset\_inpath}}{}
Extract all entities from the \emph{Freebase} relations file.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{dataset\_inpath}} (\emph{\texttt{str}}) -- Path to the \emph{Freebase} file.

\item[{Returns}] \leavevmode
Set of entities in the \emph{Freebase} relations file..

\item[{Return type}] \leavevmode
set

\end{description}\end{quote}

\end{fulllineitems}

\index{extract\_entities\_from\_tql\_file() (in module src.trans\_e.contains\_entities)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.contains_entities.extract_entities_from_tql_file}\pysiglinewithargsret{\bfcode{extract\_entities\_from\_tql\_file}}{\emph{tql\_path}}{}
Extract all entities from the \code{tql} \emph{Wikidata} \emph{Freebase} dump.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{tql\_path}} (\emph{\texttt{str}}) -- Path to \code{tql} file.

\item[{Returns}] \leavevmode
Set of entities in the \code{tql} dump.

\item[{Return type}] \leavevmode
set

\end{description}\end{quote}

\end{fulllineitems}

\index{init\_argparse() (in module src.trans\_e.contains\_entities)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.contains_entities.init_argparse}\pysiglinewithargsret{\bfcode{init\_argparse}}{}{}
\end{fulllineitems}

\index{main() (in module src.trans\_e.contains\_entities)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.contains_entities.main}\pysiglinewithargsret{\bfcode{main}}{}{}
Main function.

\end{fulllineitems}



\paragraph{src.trans\_e.differentiate\_datasets module}
\label{src.trans_e:module-src.trans_e.differentiate_datasets}\label{src.trans_e:src-trans-e-differentiate-datasets-module}\index{src.trans\_e.differentiate\_datasets (module)}
This script analyses entities of two relation datasets (e.g. \code{FB15k} and \code{GER14k}!).
\index{compare\_entities() (in module src.trans\_e.differentiate\_datasets)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.differentiate_datasets.compare_entities}\pysiglinewithargsret{\bfcode{compare\_entities}}{\emph{set1}, \emph{set2}}{}
Compares unique entities of two relation datasets.
Also determines the size of their intersection.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{set1}} (\emph{\texttt{list}}) -- List of relation triples as tuples from dataset 1.

\item {} 
\textbf{\texttt{set2}} (\emph{\texttt{list}}) -- List of relation trilpes as tuples from dataset 2.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{init\_argparse() (in module src.trans\_e.differentiate\_datasets)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.differentiate_datasets.init_argparse}\pysiglinewithargsret{\bfcode{init\_argparse}}{}{}
Initialize all possible arguments for the argument parser.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
ArgumentParser object with command line arguments for this script.

\item[{Return type}] \leavevmode
\code{argparse.ArgumentParser}

\end{description}\end{quote}

\end{fulllineitems}

\index{main() (in module src.trans\_e.differentiate\_datasets)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.differentiate_datasets.main}\pysiglinewithargsret{\bfcode{main}}{}{}
Main function

\end{fulllineitems}



\paragraph{src.trans\_e.partition\_data module}
\label{src.trans_e:src-trans-e-partition-data-module}\label{src.trans_e:module-src.trans_e.partition_data}\index{src.trans\_e.partition\_data (module)}
This script partition the data of a relation dataset like \code{FB15k} into a training, validation and test set so it
can be used by \href{https://github.com/glorotxa/SME}{TransE}.
To make sure that no relation appears in the validation or test set that didn't appear in the training set, data
will be partitioned relation-wise. To partition them intuitively is still an option, though.
\index{check\_data\_integrity() (in module src.trans\_e.partition\_data)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.partition_data.check_data_integrity}\pysiglinewithargsret{\bfcode{check\_data\_integrity}}{\emph{data\_inpath}, \emph{remove\_clones}, \emph{outpath}}{}
Check whether all triplets in the data are unique.

\end{fulllineitems}

\index{check\_set\_integrity() (in module src.trans\_e.partition\_data)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.partition_data.check_set_integrity}\pysiglinewithargsret{\bfcode{check\_set\_integrity}}{\emph{indir}}{}
Checks the integrity of given training / validation / test sets (do triples with new relations appear in the
validation or test, but not in the training set?).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{indir}} (\emph{\texttt{str}}) -- Directory of the datasets.

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_stats() (in module src.trans\_e.partition\_data)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.partition_data.get_stats}\pysiglinewithargsret{\bfcode{get\_stats}}{\emph{data}}{}
Returns some statistics about the given data, i.e. the number of unique entities, relations and
their sum.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{data}} (\emph{\texttt{list}}) -- List of relation triples as tuples.

\item[{Returns}] \leavevmode
\#entities, \#relations, \#entities + \#relations.

\item[{Return type}] \leavevmode
tuple

\end{description}\end{quote}

\end{fulllineitems}

\index{init\_argparse() (in module src.trans\_e.partition\_data)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.partition_data.init_argparse}\pysiglinewithargsret{\bfcode{init\_argparse}}{}{}
Initialize all possible arguments for the argument parser.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
ArgumentParser object with command line arguments for this script.

\item[{Return type}] \leavevmode
\code{argparse.ArgumentParser}

\end{description}\end{quote}

\end{fulllineitems}

\index{main() (in module src.trans\_e.partition\_data)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.partition_data.main}\pysiglinewithargsret{\bfcode{main}}{}{}
Main function.

\end{fulllineitems}

\index{partition\_data() (in module src.trans\_e.partition\_data)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.partition_data.partition_data}\pysiglinewithargsret{\bfcode{partition\_data}}{\emph{data}, \emph{prts}, \emph{outdir}, \emph{whole=True}}{}
\end{fulllineitems}

\index{partition\_relation\_wise() (in module src.trans\_e.partition\_data)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.partition_data.partition_relation_wise}\pysiglinewithargsret{\bfcode{partition\_relation\_wise}}{\emph{data}, \emph{prts}}{}
Partition data into training, validation and test set.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{data}} (\emph{\texttt{list}}) -- List of relation triples as tuples.

\item {} 
\textbf{\texttt{prts}} (\emph{\texttt{tuple}}) -- Tuple of floats with each number corresponding to the desired percentage of data distributed to
the corresponding set (\% train set / \% validation set / \% tets set)

\end{itemize}

\item[{Returns}] \leavevmode
Tuple of the three data sets as lists of relation triples as tuples.

\item[{Return type}] \leavevmode
tuples

\end{description}\end{quote}

\end{fulllineitems}

\index{partition\_whole() (in module src.trans\_e.partition\_data)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.partition_data.partition_whole}\pysiglinewithargsret{\bfcode{partition\_whole}}{\emph{data}, \emph{prts}}{}
\end{fulllineitems}

\index{read\_only\_relations\_into\_set() (in module src.trans\_e.partition\_data)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.partition_data.read_only_relations_into_set}\pysiglinewithargsret{\bfcode{read\_only\_relations\_into\_set}}{\emph{inpath}}{}
Only read the relation of a given relation dataset into a set.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{inpath}} (\emph{\texttt{str}}) -- Path to relation dataset.

\item[{Returns}] \leavevmode
Set of dataset relation types.

\item[{Return type}] \leavevmode
set

\end{description}\end{quote}

\end{fulllineitems}

\index{write\_data\_in\_file() (in module src.trans\_e.partition\_data)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.partition_data.write_data_in_file}\pysiglinewithargsret{\bfcode{write\_data\_in\_file}}{\emph{data}, \emph{outfile}}{}
Writes relation triples into a file.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{data}} (\emph{\texttt{list}}) -- List of relation triples as tuples.

\item {} 
\textbf{\texttt{outfile}} (\emph{\texttt{str}}) -- Path the triples should be written to.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{src.trans\_e.trans\_we module}
\label{src.trans_e:src-trans-e-trans-we-module}\label{src.trans_e:module-src.trans_e.trans_we}\index{src.trans\_e.trans\_we (module)}
This module follows a modified approach from
\href{http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf}{(Bordes et al., 2013)}.
As so, noise-contrastive learning and corrupt triples are use. But whereas in this original paper,
vector representations forn entities and relations are learned in a joint manner, in this case only the continuous
representations for semantic relations will be learned and word embeddings used for the entities instead.

\begin{notice}{warning}{Warning:}
Because we use words embedding but still the \emph{FB15k} dataset here, we can only use data samples where we have
trained word embeddings for both entities. Those are only a few, which is one reason why this approach performs
badly.
\end{notice}
\index{convert\_data() (in module src.trans\_e.trans\_we)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.trans_we.convert_data}\pysiglinewithargsret{\bfcode{convert\_data}}{\emph{sets\_path}, \emph{tql\_inpath}, \emph{vector\_inpath}}{}
Re-formats relation data sets to fit the training routine in this module.
Also tests the coverage of word embedding model on all entities in the datasets.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{sets\_path}} (\emph{\texttt{str}}) -- Directory of the datasets.

\item {} 
\textbf{\texttt{tql\_inpath}} (\emph{\texttt{str}}) -- Path to \emph{Wikidata} \emph{Freebase} dump in \titleref{tql} format.

\item {} 
\textbf{\texttt{vector\_inpath}} (\emph{\texttt{str}}) -- Path to word embedding file.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{create\_corrupt\_triples() (in module src.trans\_e.trans\_we)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.trans_we.create_corrupt_triples}\pysiglinewithargsret{\bfcode{create\_corrupt\_triples}}{\emph{grouped\_pairs}, \emph{entities}}{}
Creates a set of corrupted training triplets group by their shared relation.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{grouped\_pairs}} (\emph{\texttt{dict}}) -- Test samples as dictionary with relation as key and a list of tuples

\item {} 
\textbf{\texttt{two entities each as value.}} (\emph{\texttt{with}}) -- 

\item {} 
\textbf{\texttt{entities}} (\emph{\texttt{set}}) -- Set of unique entities.

\end{itemize}

\item[{Returns}] \leavevmode
\textbf{grouped\_train} -- Corrupted training samples as dictionary with a relation as key and a list of tuples
with two entities each as value.

\item[{Return type}] \leavevmode
dict

\end{description}\end{quote}

\end{fulllineitems}

\index{dump\_relation\_vectors() (in module src.trans\_e.trans\_we)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.trans_we.dump_relation_vectors}\pysiglinewithargsret{\bfcode{dump\_relation\_vectors}}{\emph{relation\_vectors}, \emph{outpath}}{}
Saves relation numpy vectors.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{relation\_vectors}} (\emph{\texttt{dict}}) -- Dictionary with index of a relation as key and the relations vector as a

\item {} 
\textbf{\texttt{as value.}} (\emph{\texttt{numpy.array}}) -- 

\item {} 
\textbf{\texttt{outpath}} (\emph{\texttt{str}}) -- Path the vectors should be saved to.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{evaluate() (in module src.trans\_e.trans\_we)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.trans_we.evaluate}\pysiglinewithargsret{\bfcode{evaluate}}{\emph{model}, \emph{grouped\_test}, \emph{relation\_vectors}, \emph{entities}}{}
Evaluate the relations vector the same way as in \href{http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf}{(Bordes et al.,
2013)}.
Therefore, for every relation triple in the testset, one entity will be removed and all entities will be inserted
afterwards. Also they will be ranked by their loss (ascending) and assigned a rank. The evaluation metrics are
the percentage of times the right entity is in the top ten highest ranked entities and mean rank of the correct
entitiy.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{model}} (\emph{\texttt{gensim.models.Word2Vec}}) -- Word embeddings as gensim model.

\item {} 
\textbf{\texttt{grouped\_test}} (\emph{\texttt{dict}}) -- Test samples as dictionary with relation as key and a list of tuples

\item {} 
\textbf{\texttt{two entities each as value.}} (\emph{\texttt{with}}) -- 

\item {} 
\textbf{\texttt{relation\_vectors}} (\emph{\texttt{dict}}) -- Dictionary with index of a relation as key and the relations vector as a numpy.array

\item {} 
\textbf{\texttt{value.}} (\emph{\texttt{as}}) -- 

\item {} 
\textbf{\texttt{entities}} (\emph{\texttt{set}}) -- Set of unique entities.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{extract\_data\_from\_uri() (in module src.trans\_e.trans\_we)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.trans_we.extract_data_from_uri}\pysiglinewithargsret{\bfcode{extract\_data\_from\_uri}}{\emph{uri}}{}
Extracts data from an URI.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{uri}} (\emph{\texttt{str}}) -- URI the data should be extracted from.

\item[{Returns}] \leavevmode
Extracted data.

\item[{Return type}] \leavevmode
str

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_rank() (in module src.trans\_e.trans\_we)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.trans_we.get_rank}\pysiglinewithargsret{\bfcode{get\_rank}}{\emph{target}, \emph{ranks}}{}
Get rank of a target entity within all ranked entities.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{target}} (\emph{\texttt{str}}) -- Target entity which rank should be determined.

\item {} 
\textbf{\texttt{ranks}} (\emph{\texttt{list}}) -- List of tuples of an entity and its rank.

\end{itemize}

\item[{Returns}] \leavevmode
Rank of entity or -1 if entity is not present in ranks.

\item[{Return type}] \leavevmode
int

\end{description}\end{quote}

\end{fulllineitems}

\index{init\_argparser() (in module src.trans\_e.trans\_we)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.trans_we.init_argparser}\pysiglinewithargsret{\bfcode{init\_argparser}}{}{}
Initialize all possible arguments for the argument parser.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
ArgumentParser object with command line arguments for this script.

\item[{Return type}] \leavevmode
\code{argparse.ArgumentParser}

\end{description}\end{quote}

\end{fulllineitems}

\index{load\_relation\_vectors() (in module src.trans\_e.trans\_we)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.trans_we.load_relation_vectors}\pysiglinewithargsret{\bfcode{load\_relation\_vectors}}{\emph{inpath}}{}
Loads relation numpy vectors.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{inpath}} (\emph{\texttt{str}}) -- Path the numpy vectors should be loaded from.

\item[{Returns}] \leavevmode
Dictionary with index of a relation as key and the relations vector as a numpy.array as value.

\item[{Return type}] \leavevmode
dict

\end{description}\end{quote}

\end{fulllineitems}

\index{main() (in module src.trans\_e.trans\_we)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.trans_we.main}\pysiglinewithargsret{\bfcode{main}}{}{}
Main function.

\end{fulllineitems}

\index{prepare\_training() (in module src.trans\_e.trans\_we)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.trans_we.prepare_training}\pysiglinewithargsret{\bfcode{prepare\_training}}{\emph{sets\_path}, \emph{vector\_inpath}}{}
Prepares the training step loading word embeddings and training sets.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{sets\_path}} (\emph{\texttt{str}}) -- Path to training set directory.

\item {} 
\textbf{\texttt{vector\_inpath}} (\emph{\texttt{str}}) -- Path to word embedding file.

\end{itemize}

\item[{Returns}] \leavevmode
Tuple of results with \textbf{model} (\emph{gensim.models.Word2Vec}): Word embeddings as gensim model /
\textbf{grouped\_train} (\emph{dict}): Training samples as dictionary with relation as key and a list of tuples
with two entities each as value / \textbf{grouped\_valid} (\emph{dict}): As \textbf{grouped\_train} / \textbf{grouped\_test}
(\emph{dict}): As \textbf{grouped\_train} / \textbf{grouped\_corrupted} (\emph{dict}): As \textbf{grouped\_train} /
\textbf{relations\_types} (\emph{dict}): Dictionary with relations as key and the amount of triples with this relation
as a key / \textbf{entities} (\emph{set}): Set of unique entities.

\item[{Return type}] \leavevmode
tuple

\end{description}\end{quote}

\end{fulllineitems}

\index{rank\_entities() (in module src.trans\_e.trans\_we)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.trans_we.rank_entities}\pysiglinewithargsret{\bfcode{rank\_entities}}{\emph{reference}, \emph{solution}, \emph{model}, \emph{entities}}{}
Ranks entities against a reference vector.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{reference}} (\emph{\texttt{numpy.array}}) -- Reference vector.

\item {} 
\textbf{\texttt{solution}} (\emph{\texttt{str}}) -- The actual solution.

\item {} 
\textbf{\texttt{model}} (\emph{\texttt{gensim.models.Word2Vec}}) -- Word embeddings as gensim model.

\item {} 
\textbf{\texttt{entities}} (\emph{\texttt{set}}) -- Set of unique entities.

\end{itemize}

\item[{Returns}] \leavevmode
Rank of solution as integer, flag if a \href{mailto:Hit@10}{Hit@10} has occurred as boolean.

\item[{Return type}] \leavevmode
tuples

\end{description}\end{quote}

\end{fulllineitems}

\index{read\_freebase\_data() (in module src.trans\_e.trans\_we)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.trans_we.read_freebase_data}\pysiglinewithargsret{\bfcode{read\_freebase\_data}}{\emph{sets\_path}}{}
Reads all different datasets in a directory at once.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{sets\_path}} (\emph{\texttt{str}}) -- Directory of the datasets.

\item[{Returns}] \leavevmode
Tuple of datasets as lists.

\item[{Return type}] \leavevmode
tuple

\end{description}\end{quote}

\end{fulllineitems}

\index{read\_tql\_file() (in module src.trans\_e.trans\_we)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.trans_we.read_tql_file}\pysiglinewithargsret{\bfcode{read\_tql\_file}}{\emph{tql\_inpath}}{}
Reads a \emph{Freebase} dump by wikidata. Must be in \titleref{tql} format. Available online
\href{https://developers.google.com/freebase/}{here} (July 2016).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{tql\_inpath}} (\emph{\texttt{str}}) -- Path to \emph{Wikidata} \emph{Freebase} dump in \titleref{tql} format.

\item[{Returns}] \leavevmode
Dictionary with \emph{Freebase} code as key and the corresponding real name of an entity as value.

\item[{Return type}] \leavevmode
defaultdict

\end{description}\end{quote}

\end{fulllineitems}

\index{test\_coverage() (in module src.trans\_e.trans\_we)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.trans_we.test_coverage}\pysiglinewithargsret{\bfcode{test\_coverage}}{\emph{triples}, \emph{model}}{}
Test the coverage of a dataset consisting of freebase triples on word2vec word embeddings.
For every triple (h, l, t), the entities h and t are taken and used for look up in the word2vec
model.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{triples}} (\emph{\texttt{list}}) -- List of relation triples as tuples.

\item {} 
\textbf{\texttt{model}} (\emph{\texttt{gensim.models.Word2Vec}}) -- Word embeddings as gensim model.

\end{itemize}

\item[{Returns}] \leavevmode
Set of entities in the model.

\item[{Return type}] \leavevmode
set

\end{description}\end{quote}

\end{fulllineitems}

\index{train() (in module src.trans\_e.trans\_we)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.trans_we.train}\pysiglinewithargsret{\bfcode{train}}{\emph{model}, \emph{grouped\_train}, \emph{grouped\_corrupted}, \emph{lossf}, \emph{relation\_types}, \emph{epochs=1000}, \emph{learning\_rate=0.01}, \emph{margin=1.0}}{}
Train the relation vectors following the example of \href{http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf}{(Bordes et al.,
2013)},
but use word embeddings for the entity vectors instead.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{model}} (\emph{gensim.models.Word2Vec}) -- Word embeddings as gensim model.

\item {} 
\textbf{\texttt{grouped\_train}} (\emph{\texttt{dict}}) -- Training samples as dictionary with relation as key and a list of tuples

\item {} 
\textbf{\texttt{two entities each as value.}} (\emph{\texttt{with}}) -- 

\item {} 
\textbf{\texttt{grouped\_corrupted}} (\emph{\texttt{dict}}) -- As grouped\_train.

\item {} 
\textbf{\texttt{lossf}} (\emph{\texttt{func}}) -- Loss function for training.

\item {} 
\textbf{\texttt{relation\_types}} (\emph{\texttt{dict}}) -- Dictionary with relations as key and the amount of triples with this relation as a key.

\item {} 
\textbf{\texttt{epochs}} (\emph{\texttt{int}}) -- Number of training epochs.

\item {} 
\textbf{\texttt{learning\_rate}} (\emph{\texttt{float}}) -- Learning rate for training.

\item {} 
\textbf{\texttt{margin}} (\emph{\texttt{float}}) -- Margin \(\gamma\) for training.

\end{itemize}

\item[{Returns}] \leavevmode
Dictionary with index of a relation as key and the relations vector as a numpy.array as value.

\item[{Return type}] \leavevmode
dict

\end{description}\end{quote}

\end{fulllineitems}

\index{transform\_triples() (in module src.trans\_e.trans\_we)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.trans_we.transform_triples}\pysiglinewithargsret{\bfcode{transform\_triples}}{\emph{triples}, \emph{relation\_types}, \emph{entities}}{}
Groups a list of relations triples by their relations and returns a suitable data structure.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{triples}} (\emph{\texttt{list}}) -- List of relation triples as tuples.

\item {} 
\textbf{\texttt{relation\_types}} (\emph{\texttt{dict}}) -- Dictionary with relations as key and the amount of triples with this relation as a key.

\item {} 
\textbf{\texttt{entities}} (\emph{\texttt{set}}) -- Set of unique entities.

\end{itemize}

\item[{Returns}] \leavevmode
\begin{description}
\item[{Dictionary with relation as key and a list of entity tuples as value and an augmented set of unique}] \leavevmode
entities.

\end{description}


\item[{Return type}] \leavevmode
tuple

\end{description}\end{quote}

\end{fulllineitems}

\index{write\_data() (in module src.trans\_e.trans\_we)}

\begin{fulllineitems}
\phantomsection\label{src.trans_e:src.trans_e.trans_we.write_data}\pysiglinewithargsret{\bfcode{write\_data}}{\emph{triples}, \emph{found\_entities}, \emph{outpath}}{}
Writes relation triples into a file, but only those triples where both entities are also found in a designated
set.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{triples}} (\emph{\texttt{list}}) -- List of relation triples as tuples.

\item {} 
\textbf{\texttt{found\_entities}} (\emph{\texttt{set}}) -- Set of unique entities.

\item {} 
\textbf{\texttt{outpath}} (\emph{\texttt{str}}) -- Path the data should be written to.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{Module contents}
\label{src:module-src}\label{src:module-contents}\index{src (module)}

\chapter{Indices and tables}
\label{index:indices-and-tables}\begin{itemize}
\item {} 
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\DUrole{xref,std,std-ref}{search}

\end{itemize}


\renewcommand{\indexname}{Python Module Index}
\begin{theindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{s}
\item {\texttt{src}}, \pageref{src:module-src}
\item {\texttt{src.clustering}}, \pageref{src.clustering:module-src.clustering}
\item {\texttt{src.clustering.cluster\_mappings}}, \pageref{src.clustering:module-src.clustering.cluster_mappings}
\item {\texttt{src.eval}}, \pageref{src.eval:module-src.eval}
\item {\texttt{src.eval.analogy}}, \pageref{src.eval:module-src.eval.analogy}
\item {\texttt{src.eval.eval\_vectors}}, \pageref{src.eval:module-src.eval.eval_vectors}
\item {\texttt{src.eval.word\_similarity}}, \pageref{src.eval:module-src.eval.word_similarity}
\item {\texttt{src.mapping}}, \pageref{src.mapping:module-src.mapping}
\item {\texttt{src.mapping.mapthreading}}, \pageref{src.mapping:module-src.mapping.mapthreading}
\item {\texttt{src.misc}}, \pageref{src.misc:module-src.misc}
\item {\texttt{src.misc.decorators}}, \pageref{src.misc:module-src.misc.decorators}
\item {\texttt{src.misc.helpers}}, \pageref{src.misc:module-src.misc.helpers}
\item {\texttt{src.prep}}, \pageref{src.prep:module-src.prep}
\item {\texttt{src.prep.corpus}}, \pageref{src.prep.corpus:module-src.prep.corpus}
\item {\texttt{src.prep.corpus.convert\_to\_plain}}, \pageref{src.prep.corpus:module-src.prep.corpus.convert_to_plain}
\item {\texttt{src.prep.corpus.extract\_conll}}, \pageref{src.prep.corpus:module-src.prep.corpus.extract_conll}
\item {\texttt{src.prep.corpus.mapper}}, \pageref{src.prep.corpus:module-src.prep.corpus.mapper}
\item {\texttt{src.prep.corpus.reducer}}, \pageref{src.prep.corpus:module-src.prep.corpus.reducer}
\item {\texttt{src.prep.nes}}, \pageref{src.prep.nes:module-src.prep.nes}
\item {\texttt{src.prep.nes.extract\_nes}}, \pageref{src.prep.nes:module-src.prep.nes.extract_nes}
\item {\texttt{src.prep.nes.merge}}, \pageref{src.prep.nes:module-src.prep.nes.merge}
\item {\texttt{src.prep.nes.statistics}}, \pageref{src.prep.nes:module-src.prep.nes.statistics}
\item {\texttt{src.prep.relations}}, \pageref{src.prep.relations:module-src.prep.relations}
\item {\texttt{src.prep.relations.relations}}, \pageref{src.prep.relations:module-src.prep.relations.relations}
\item {\texttt{src.trans\_e.add\_inverse\_relations}}, \pageref{src.trans_e:module-src.trans_e.add_inverse_relations}
\item {\texttt{src.trans\_e.contains\_entities}}, \pageref{src.trans_e:module-src.trans_e.contains_entities}
\item {\texttt{src.trans\_e.differentiate\_datasets}}, \pageref{src.trans_e:module-src.trans_e.differentiate_datasets}
\item {\texttt{src.trans\_e.partition\_data}}, \pageref{src.trans_e:module-src.trans_e.partition_data}
\item {\texttt{src.trans\_e.trans\_we}}, \pageref{src.trans_e:module-src.trans_e.trans_we}
\end{theindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}
